{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:35.212771Z",
     "start_time": "2018-06-28T18:24:35.179928Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T19:58:42.041134Z",
     "start_time": "2018-06-28T19:58:41.217922Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:36.543770Z",
     "start_time": "2018-06-28T18:24:36.529788Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:37.061272Z",
     "start_time": "2018-06-28T18:24:36.909001Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.frecency import sample, frecency_points\n",
    "from data.frecency import sample_suggestions_normal as sample_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "This section is mostly to check that's it possible to fit a linear model perfectly to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:38.009063Z",
     "start_time": "2018-06-28T18:24:37.736520Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a model, we sample a lot of these scores and also add noise on top to make the problem more similar to the real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:38.733630Z",
     "start_time": "2018-06-28T18:24:38.419443Z"
    }
   },
   "outputs": [],
   "source": [
    "n = int(1e6)\n",
    "noise = np.random.normal(0, 2, size=(n))\n",
    "X, y = sample(n)\n",
    "y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:39.590734Z",
     "start_time": "2018-06-28T18:24:38.787659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting coefficients are extremely close to the actual frecency weights. How close they are depends on how much noise we add to the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:40.057795Z",
     "start_time": "2018-06-28T18:24:40.035660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(120.00333500654246, 120.0),\n",
       " (35.995557550483873, 36.0),\n",
       " (97.994996557300183, 98.0),\n",
       " (13.992650899036075, 14.0),\n",
       " (19.993039069792342, 20.0),\n",
       " (99.97600899995517, 100.0),\n",
       " (140.00937856149761, 140.0),\n",
       " (69.999480626657714, 70.0),\n",
       " (199.99165543624855, 200.0),\n",
       " (42.001243539264372, 42.0),\n",
       " (60.007903363545338, 60.0),\n",
       " (140.01511441895124, 140.0),\n",
       " (11.991131134526411, 12.0),\n",
       " (60.002935871815112, 60.0),\n",
       " (84.003882561214098, 84.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(model.coef_, frecency_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:40.444619Z",
     "start_time": "2018-06-28T18:24:40.425463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00333501, -0.00444245, -0.00500344, -0.0073491 , -0.00696093,\n",
       "       -0.023991  ,  0.00937856, -0.00051937, -0.00834456,  0.00124354,\n",
       "        0.00790336,  0.01511442, -0.00886887,  0.00293587,  0.00388256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ - frecency_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and SVM loss\n",
    "\n",
    "Now, we make the problem slightly more difficult: Instead of just learning the frecency function from data, we try to learn it from user interactions. The training data now consists of a variable number of history suggestions and their respective features. The label corresponds to the suggestion that the user clicked on. We still assume that the user clicks on the item with the highest frecency score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent generally works better when the data is centered around the origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:41.995923Z",
     "start_time": "2018-06-28T18:24:41.977991Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:49.195483Z",
     "start_time": "2018-06-28T18:24:42.378264Z"
    }
   },
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:50.117491Z",
     "start_time": "2018-06-28T18:24:50.028430Z"
    }
   },
   "outputs": [],
   "source": [
    "from optimizers import GradientDescent, AdaptiveGradientDescent, DecayedGradientDescent, RProp, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss (SVM loss)\n",
    "\n",
    "To supervise training, we keep logging the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:50.965899Z",
     "start_time": "2018-06-28T18:24:50.945085Z"
    }
   },
   "outputs": [],
   "source": [
    "def svm_loss(preds, ys, delta=0):\n",
    "    correct = ys.argmax()\n",
    "    score_correct = preds[correct]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i, pred in enumerate(preds):\n",
    "        loss += max(0, pred + delta - score_correct)            \n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we want to supervise the learning process and save the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:51.765761Z",
     "start_time": "2018-06-28T18:24:51.747734Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy needs to be measured carefully here: In our simulation, we assume that the current frecency is the perfect ranking function. But because items sometimes get the same frecency scores, there can be more than one correct answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:53.435079Z",
     "start_time": "2018-06-28T18:24:53.414878Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_accuracy(y, preds):\n",
    "    correct = 0.\n",
    "    \n",
    "    for yi, pi in zip(y, preds):\n",
    "        if yi[pi.argmax()] == yi.max():\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SVMRanking` class is the main mechanism for fitting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:24:53.941383Z",
     "start_time": "2018-06-28T18:24:53.891826Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVMRanking:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "        \n",
    "    def fit(self, data_generator, optimizer, num_iterations=10, callbacks=[]):\n",
    "        X, y = data_generator(1)\n",
    "        num_features = X[0].shape[1]\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "        \n",
    "        for j in range(num_iterations):\n",
    "            X, y = data_generator(4000)\n",
    "            \n",
    "            preds = self.predict(X)\n",
    "            gradient = np.zeros(num_features)\n",
    "\n",
    "            for xi, pi, yi in zip(X, preds, y):\n",
    "                correct = yi.argmax()\n",
    "                score_correct = pi[correct]\n",
    "\n",
    "                for i, predicted_score in enumerate(pi):\n",
    "                    gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            gradient /= len(X)\n",
    "            \n",
    "            loss = np.mean([svm_loss(pi, yi) for pi, yi in zip(self.predict(X), y)])\n",
    "            accuracy = rank_accuracy(y, model.predict(X))\n",
    "            \n",
    "            print(\"[%d/%d] training: %.5f loss, %.3f accuracy\" % (j + 1, num_iterations, loss, accuracy))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T18:28:03.334755Z",
     "start_time": "2018-06-28T18:26:58.758657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 11.71683 loss, 0.738 accuracy\n",
      "[ModelCheckpoint] New best model with 0.73150 validation accuracy\n",
      "[2/48] training: 122.41008 loss, 0.731 accuracy\n",
      "validation: 0.721 accuracy\n",
      "[3/48] training: 55.80964 loss, 0.906 accuracy\n",
      "[ModelCheckpoint] New best model with 0.91160 validation accuracy\n",
      "[4/48] training: 6.76885 loss, 0.954 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95830 validation accuracy\n",
      "[5/48] training: 2.21581 loss, 0.958 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96020 validation accuracy\n",
      "[6/48] training: 1.10265 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96490 validation accuracy\n",
      "[7/48] training: 0.85294 loss, 0.981 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98130 validation accuracy\n",
      "[8/48] training: 0.57912 loss, 0.980 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[9/48] training: 0.32446 loss, 0.982 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[10/48] training: 0.32911 loss, 0.980 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98140 validation accuracy\n",
      "[11/48] training: 0.19747 loss, 0.982 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[12/48] training: 0.20725 loss, 0.976 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[13/48] training: 0.13382 loss, 0.979 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[14/48] training: 0.12088 loss, 0.981 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[15/48] training: 0.14444 loss, 0.980 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[16/48] training: 0.07397 loss, 0.981 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[17/48] training: 0.11807 loss, 0.980 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98220 validation accuracy\n",
      "[18/48] training: 0.10564 loss, 0.977 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[19/48] training: 0.05892 loss, 0.980 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[20/48] training: 0.05180 loss, 0.981 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98290 validation accuracy\n",
      "[21/48] training: 0.04937 loss, 0.980 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[22/48] training: 0.06325 loss, 0.977 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[23/48] training: 0.02504 loss, 0.982 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[24/48] training: 0.04105 loss, 0.981 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[25/48] training: 0.03999 loss, 0.978 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[26/48] training: 0.04406 loss, 0.980 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[27/48] training: 0.03507 loss, 0.981 accuracy\n",
      "validation: 0.983 accuracy\n",
      "[28/48] training: 0.03034 loss, 0.978 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[29/48] training: 0.02061 loss, 0.978 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[30/48] training: 0.02439 loss, 0.979 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[31/48] training: 0.01800 loss, 0.977 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[32/48] training: 0.01398 loss, 0.981 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[33/48] training: 0.01017 loss, 0.981 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[34/48] training: 0.01032 loss, 0.985 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[35/48] training: 0.00939 loss, 0.980 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[36/48] training: 0.01502 loss, 0.977 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[37/48] training: 0.00746 loss, 0.979 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[38/48] training: 0.00704 loss, 0.979 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[39/48] training: 0.00586 loss, 0.982 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[40/48] training: 0.00901 loss, 0.981 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[41/48] training: 0.00558 loss, 0.981 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[42/48] training: 0.00382 loss, 0.980 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[43/48] training: 0.00282 loss, 0.980 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[44/48] training: 0.00435 loss, 0.979 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[45/48] training: 0.00344 loss, 0.981 accuracy\n",
      "validation: 0.982 accuracy\n",
      "[46/48] training: 0.00313 loss, 0.976 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[47/48] training: 0.00344 loss, 0.982 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[48/48] training: 0.00299 loss, 0.983 accuracy\n",
      "validation: 0.982 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T19:55:46.045733Z",
     "start_time": "2018-06-28T19:54:41.976066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 11.71683 loss, 0.738 accuracy\n",
      "[ModelCheckpoint] New best model with 0.73150 validation accuracy\n",
      "[2/48] training: 13.43970 loss, 0.728 accuracy\n",
      "validation: 0.721 accuracy\n",
      "[3/48] training: 11.48569 loss, 0.748 accuracy\n",
      "[ModelCheckpoint] New best model with 0.73510 validation accuracy\n",
      "[4/48] training: 11.15089 loss, 0.749 accuracy\n",
      "validation: 0.734 accuracy\n",
      "[5/48] training: 11.64325 loss, 0.739 accuracy\n",
      "[ModelCheckpoint] New best model with 0.74280 validation accuracy\n",
      "[6/48] training: 10.64545 loss, 0.849 accuracy\n",
      "[ModelCheckpoint] New best model with 0.84070 validation accuracy\n",
      "[7/48] training: 10.95008 loss, 0.839 accuracy\n",
      "validation: 0.837 accuracy\n",
      "[8/48] training: 11.11485 loss, 0.834 accuracy\n",
      "validation: 0.838 accuracy\n",
      "[9/48] training: 9.85802 loss, 0.845 accuracy\n",
      "validation: 0.829 accuracy\n",
      "[10/48] training: 10.26959 loss, 0.839 accuracy\n",
      "validation: 0.839 accuracy\n",
      "[11/48] training: 10.19416 loss, 0.834 accuracy\n",
      "validation: 0.840 accuracy\n",
      "[12/48] training: 8.56436 loss, 0.838 accuracy\n",
      "validation: 0.838 accuracy\n",
      "[13/48] training: 8.43679 loss, 0.836 accuracy\n",
      "validation: 0.837 accuracy\n",
      "[14/48] training: 7.54865 loss, 0.838 accuracy\n",
      "validation: 0.838 accuracy\n",
      "[15/48] training: 6.76996 loss, 0.846 accuracy\n",
      "[ModelCheckpoint] New best model with 0.84470 validation accuracy\n",
      "[16/48] training: 6.35255 loss, 0.836 accuracy\n",
      "validation: 0.841 accuracy\n",
      "[17/48] training: 5.25627 loss, 0.845 accuracy\n",
      "validation: 0.841 accuracy\n",
      "[18/48] training: 4.95672 loss, 0.836 accuracy\n",
      "validation: 0.842 accuracy\n",
      "[19/48] training: 3.83310 loss, 0.847 accuracy\n",
      "[ModelCheckpoint] New best model with 0.85160 validation accuracy\n",
      "[20/48] training: 3.37146 loss, 0.852 accuracy\n",
      "[ModelCheckpoint] New best model with 0.86440 validation accuracy\n",
      "[21/48] training: 3.19823 loss, 0.859 accuracy\n",
      "[ModelCheckpoint] New best model with 0.86970 validation accuracy\n",
      "[22/48] training: 2.33854 loss, 0.868 accuracy\n",
      "validation: 0.859 accuracy\n",
      "[23/48] training: 2.25716 loss, 0.868 accuracy\n",
      "validation: 0.864 accuracy\n",
      "[24/48] training: 1.64944 loss, 0.868 accuracy\n",
      "validation: 0.863 accuracy\n",
      "[25/48] training: 1.81462 loss, 0.868 accuracy\n",
      "validation: 0.868 accuracy\n",
      "[26/48] training: 1.41966 loss, 0.950 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94650 validation accuracy\n",
      "[27/48] training: 1.26415 loss, 0.948 accuracy\n",
      "validation: 0.946 accuracy\n",
      "[28/48] training: 0.97492 loss, 0.945 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94890 validation accuracy\n",
      "[29/48] training: 0.69980 loss, 0.961 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95650 validation accuracy\n",
      "[30/48] training: 0.63502 loss, 0.949 accuracy\n",
      "validation: 0.948 accuracy\n",
      "[31/48] training: 0.45750 loss, 0.954 accuracy\n",
      "validation: 0.951 accuracy\n",
      "[32/48] training: 0.38181 loss, 0.948 accuracy\n",
      "validation: 0.953 accuracy\n",
      "[33/48] training: 0.30913 loss, 0.942 accuracy\n",
      "validation: 0.946 accuracy\n",
      "[34/48] training: 0.19486 loss, 0.970 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96670 validation accuracy\n",
      "[35/48] training: 0.12802 loss, 0.889 accuracy\n",
      "validation: 0.894 accuracy\n",
      "[36/48] training: 0.12336 loss, 0.969 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97210 validation accuracy\n",
      "[37/48] training: 0.04596 loss, 0.970 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[38/48] training: 0.04869 loss, 0.973 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[39/48] training: 0.04960 loss, 0.970 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[40/48] training: 0.03582 loss, 0.964 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[41/48] training: 0.03337 loss, 0.973 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97330 validation accuracy\n",
      "[42/48] training: 0.01440 loss, 0.971 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[43/48] training: 0.01551 loss, 0.973 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[44/48] training: 0.01612 loss, 0.971 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[45/48] training: 0.00739 loss, 0.972 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[46/48] training: 0.00419 loss, 0.975 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[47/48] training: 0.00507 loss, 0.971 accuracy\n",
      "validation: 0.971 accuracy\n",
      "[48/48] training: 0.00589 loss, 0.974 accuracy\n",
      "validation: 0.971 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "opt = AdaptiveGradientDescent(0.1, len(frecency_points))\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=opt,\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy,  sample_suggestions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can compare the learned weights with the true frecency scores. Note that the values themselves are very different now but that the ordering is nearly the same as in the real algorithm. This shows that we are ranking very similarly to the real algorithm but that the optimization process did not fully reach the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T19:57:03.107759Z",
     "start_time": "2018-06-28T19:57:03.051039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 14.328107294741949),\n",
       " (14.0, 10.147936225293185),\n",
       " (20.0, 34.335460264505343),\n",
       " (36.0, 34.335334892244539),\n",
       " (42.0, 34.338056202528762),\n",
       " (60.0, 34.335892421808076),\n",
       " (60.0, 34.350521497586705),\n",
       " (70.0, 34.335328740904643),\n",
       " (84.0, 61.827233423435842),\n",
       " (98.0, 61.827444877537495),\n",
       " (100.0, 61.827442586893319),\n",
       " (120.0, 116.45108591309054),\n",
       " (140.0, 116.45141094451398),\n",
       " (140.0, 116.45498071467374),\n",
       " (200.0, 244.46689170495839)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais = np.argsort(frecency_points)\n",
    "zip(frecency_points[ais], model.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, the model is correct most of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T19:57:07.387570Z",
     "start_time": "2018-06-28T19:57:06.482259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = sample_suggestions(10000)\n",
    "rank_accuracy(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: Evaluation during training in production\n",
    "\n",
    "If we only use 400 data points for validating the current model, then this is not enough to properly assess the model quality.\n",
    "The accuracies jump too much.\n",
    "However, this evaluation could still be used to test that the model is not completely off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T19:59:18.663021Z",
     "start_time": "2018-06-28T19:58:45.495749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   3.,   10.,   30.,  114.,  189.,  234.,  308.,   81.,   26.,    4.]),\n",
       " array([ 0.94   ,  0.94575,  0.9515 ,  0.95725,  0.963  ,  0.96875,\n",
       "         0.9745 ,  0.98025,  0.986  ,  0.99175,  0.9975 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAFkCAYAAAB4sKK5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqO7WV+97AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d480df390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = sample_suggestions(1000 * 400)\n",
    "accuracies = []\n",
    "\n",
    "for i in range(0, len(X) - 400, 400):\n",
    "    Xi, yi = X[i:i+400], y[i:i+400]\n",
    "    acc = rank_accuracy(yi, model.predict(Xi))\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "plt.hist(sorted(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency\n",
    "\n",
    "We still need to take into account that users visit links more than once.\n",
    "How often a user visits a link is sampled from an exponential distribution in this simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T19:59:59.923769Z",
     "start_time": "2018-06-28T19:59:59.656552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 496.,  259.,  118.,   61.,   31.,   15.,    9.,    5.,    2.,    4.]),\n",
       " array([  0. ,   4.9,   9.8,  14.7,  19.6,  24.5,  29.4,  34.3,  39.2,\n",
       "         44.1,  49. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d2bdf2c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequencies = np.int32(np.random.exponential(7, size=(1000)))\n",
    "plt.hist(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:00:02.696380Z",
     "start_time": "2018-06-28T20:00:02.670029Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_url_features(num_samples):\n",
    "    frequencies = np.int32(np.random.exponential(7, size=num_samples)) + 1\n",
    "    frequencies = np.int32(np.ones(num_samples))\n",
    "    X = []\n",
    "    \n",
    "    for frequency in frequencies:\n",
    "        num_sampled = min(10, frequency)\n",
    "        features = sample_weighted(num_sampled, weights).sum(axis=0)\n",
    "        X.append(frequency / num_sampled * features)\n",
    "        \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:01:26.276975Z",
     "start_time": "2018-06-28T20:00:22.085883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 10.96645 loss, 0.742 accuracy\n",
      "[ModelCheckpoint] New best model with 0.73000 validation accuracy\n",
      "[2/48] training: 2.53767 loss, 0.917 accuracy\n",
      "[ModelCheckpoint] New best model with 0.92450 validation accuracy\n",
      "[3/48] training: 0.92663 loss, 0.934 accuracy\n",
      "[ModelCheckpoint] New best model with 0.93510 validation accuracy\n",
      "[4/48] training: 0.31598 loss, 0.948 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94480 validation accuracy\n",
      "[5/48] training: 0.25366 loss, 0.950 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94820 validation accuracy\n",
      "[6/48] training: 0.13407 loss, 0.959 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95080 validation accuracy\n",
      "[7/48] training: 0.13610 loss, 0.954 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95680 validation accuracy\n",
      "[8/48] training: 0.11580 loss, 0.952 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[9/48] training: 0.07629 loss, 0.954 accuracy\n",
      "validation: 0.956 accuracy\n",
      "[10/48] training: 0.08351 loss, 0.956 accuracy\n",
      "validation: 0.953 accuracy\n",
      "[11/48] training: 0.05824 loss, 0.958 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[12/48] training: 0.05965 loss, 0.955 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95760 validation accuracy\n",
      "[13/48] training: 0.03941 loss, 0.956 accuracy\n",
      "validation: 0.954 accuracy\n",
      "[14/48] training: 0.03552 loss, 0.955 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95810 validation accuracy\n",
      "[15/48] training: 0.04687 loss, 0.950 accuracy\n",
      "validation: 0.958 accuracy\n",
      "[16/48] training: 0.02949 loss, 0.971 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96730 validation accuracy\n",
      "[17/48] training: 0.03390 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96850 validation accuracy\n",
      "[18/48] training: 0.02729 loss, 0.968 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96960 validation accuracy\n",
      "[19/48] training: 0.02786 loss, 0.965 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[20/48] training: 0.02110 loss, 0.967 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[21/48] training: 0.01320 loss, 0.970 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[22/48] training: 0.01418 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96990 validation accuracy\n",
      "[23/48] training: 0.00934 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[24/48] training: 0.01123 loss, 0.977 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97540 validation accuracy\n",
      "[25/48] training: 0.00969 loss, 0.973 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97700 validation accuracy\n",
      "[26/48] training: 0.00723 loss, 0.980 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[27/48] training: 0.00981 loss, 0.976 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[28/48] training: 0.00641 loss, 0.978 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97800 validation accuracy\n",
      "[29/48] training: 0.00493 loss, 0.974 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[30/48] training: 0.00503 loss, 0.976 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[31/48] training: 0.00742 loss, 0.975 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[32/48] training: 0.00331 loss, 0.976 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[33/48] training: 0.00417 loss, 0.978 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[34/48] training: 0.00401 loss, 0.977 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[35/48] training: 0.00231 loss, 0.970 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[36/48] training: 0.00206 loss, 0.976 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[37/48] training: 0.00242 loss, 0.981 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[38/48] training: 0.00161 loss, 0.980 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[39/48] training: 0.00157 loss, 0.974 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[40/48] training: 0.00192 loss, 0.976 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[41/48] training: 0.00155 loss, 0.980 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98280 validation accuracy\n",
      "[42/48] training: 0.00195 loss, 0.985 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98290 validation accuracy\n",
      "[43/48] training: 0.00154 loss, 0.986 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98410 validation accuracy\n",
      "[44/48] training: 0.00111 loss, 0.985 accuracy\n",
      "validation: 0.984 accuracy\n",
      "[45/48] training: 0.00115 loss, 0.985 accuracy\n",
      "validation: 0.983 accuracy\n",
      "[46/48] training: 0.00080 loss, 0.983 accuracy\n",
      "validation: 0.982 accuracy\n",
      "[47/48] training: 0.00107 loss, 0.983 accuracy\n",
      "validation: 0.983 accuracy\n",
      "[48/48] training: 0.00087 loss, 0.986 accuracy\n",
      "validation: 0.982 accuracy\n"
     ]
    }
   ],
   "source": [
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning\n",
    "\n",
    "To implement a federated version of the model above, we have to create a `Client` class that completely encapsulates training data. Only the `Client` can compute gradients based on its own data. While the `Server` is the main class for controlling the training process, it can only request gradients from clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:01:26.329494Z",
     "start_time": "2018-06-28T20:01:26.279253Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:01:26.474925Z",
     "start_time": "2018-06-28T20:01:26.331696Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        \n",
    "        num_features = len(frecency_points)\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "    \n",
    "    def fit(self, optimizer, num_iterations, num_clients_per_iteration, callbacks=[]):\n",
    "        for j in range(num_iterations):\n",
    "            clients = random.sample(self.clients, num_clients_per_iteration)\n",
    "            updates, losses = zip(*[client.request_update(self) for client in clients])\n",
    "            \n",
    "            gradient = np.mean(updates, axis=0)\n",
    "            loss = np.mean(losses, axis=0)\n",
    "            \n",
    "            print(\"[%d/%d] training loss across clients %.5f\" % (j + 1, num_iterations, loss))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:01:26.610674Z",
     "start_time": "2018-06-28T20:01:26.476914Z"
    }
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model):\n",
    "        X, y = self.data_generator()\n",
    "        preds = model.predict(X)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = np.zeros(num_features)\n",
    "        loss = 0\n",
    "\n",
    "        for xi, pi, yi in zip(X, preds, y):\n",
    "            correct = yi.argmax()\n",
    "            score_correct = pi[correct]\n",
    "\n",
    "            for i, predicted_score in enumerate(pi):\n",
    "                gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            loss += svm_loss(pi, yi)\n",
    "                \n",
    "        gradient /= len(X)\n",
    "        loss /= len(X)\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many data points a user has in each round is sampled from the following exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:01:26.976189Z",
     "start_time": "2018-06-28T20:01:26.612622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 718.,  198.,   64.,    0.,   11.,    7.,    0.,    1.,    0.,    1.]),\n",
       " array([ 1. ,  1.7,  2.4,  3.1,  3.8,  4.5,  5.2,  5.9,  6.6,  7.3,  8. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEiSpCZDgiRJajIkSJKkJkOCJElq+v/ka7VXz+AOGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d2c1e9e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = np.int32(np.random.exponential(.8, size=(1000))) + 1\n",
    "plt.hist(num_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5000 clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:02:07.322005Z",
     "start_time": "2018-06-28T20:02:07.288727Z"
    }
   },
   "outputs": [],
   "source": [
    "clients = [Client(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 1)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T20:02:59.026373Z",
     "start_time": "2018-06-28T20:02:17.097306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 6.35107\n",
      "[ModelCheckpoint] New best model with 0.77460 validation accuracy\n",
      "[2/48] training loss across clients 8.79592\n",
      "[ModelCheckpoint] New best model with 0.92450 validation accuracy\n",
      "[3/48] training loss across clients 3.18923\n",
      "validation: 0.924 accuracy\n",
      "[4/48] training loss across clients 1.12846\n",
      "[ModelCheckpoint] New best model with 0.95640 validation accuracy\n",
      "[5/48] training loss across clients 0.71365\n",
      "validation: 0.956 accuracy\n",
      "[6/48] training loss across clients 0.36722\n",
      "validation: 0.955 accuracy\n",
      "[7/48] training loss across clients 0.43015\n",
      "validation: 0.955 accuracy\n",
      "[8/48] training loss across clients 0.09179\n",
      "[ModelCheckpoint] New best model with 0.95710 validation accuracy\n",
      "[9/48] training loss across clients 0.10533\n",
      "[ModelCheckpoint] New best model with 0.95750 validation accuracy\n",
      "[10/48] training loss across clients 0.07912\n",
      "[ModelCheckpoint] New best model with 0.96080 validation accuracy\n",
      "[11/48] training loss across clients 0.05718\n",
      "validation: 0.956 accuracy\n",
      "[12/48] training loss across clients 0.05109\n",
      "validation: 0.958 accuracy\n",
      "[13/48] training loss across clients 0.07113\n",
      "validation: 0.958 accuracy\n",
      "[14/48] training loss across clients 0.01562\n",
      "validation: 0.957 accuracy\n",
      "[15/48] training loss across clients 0.03127\n",
      "[ModelCheckpoint] New best model with 0.96300 validation accuracy\n",
      "[16/48] training loss across clients 0.04024\n",
      "validation: 0.955 accuracy\n",
      "[17/48] training loss across clients 0.05899\n",
      "validation: 0.955 accuracy\n",
      "[18/48] training loss across clients 0.04991\n",
      "validation: 0.955 accuracy\n",
      "[19/48] training loss across clients 0.04651\n",
      "validation: 0.962 accuracy\n",
      "[20/48] training loss across clients 0.01611\n",
      "validation: 0.959 accuracy\n",
      "[21/48] training loss across clients 0.01536\n",
      "validation: 0.960 accuracy\n",
      "[22/48] training loss across clients 0.00382\n",
      "validation: 0.958 accuracy\n",
      "[23/48] training loss across clients 0.01193\n",
      "validation: 0.961 accuracy\n",
      "[24/48] training loss across clients 0.00402\n",
      "[ModelCheckpoint] New best model with 0.96400 validation accuracy\n",
      "[25/48] training loss across clients 0.01917\n",
      "validation: 0.957 accuracy\n",
      "[26/48] training loss across clients 0.00853\n",
      "validation: 0.961 accuracy\n",
      "[27/48] training loss across clients 0.00749\n",
      "validation: 0.961 accuracy\n",
      "[28/48] training loss across clients 0.01850\n",
      "validation: 0.963 accuracy\n",
      "[29/48] training loss across clients 0.00719\n",
      "validation: 0.961 accuracy\n",
      "[30/48] training loss across clients 0.00695\n",
      "validation: 0.961 accuracy\n",
      "[31/48] training loss across clients 0.01453\n",
      "validation: 0.964 accuracy\n",
      "[32/48] training loss across clients 0.00466\n",
      "[ModelCheckpoint] New best model with 0.96460 validation accuracy\n",
      "[33/48] training loss across clients 0.00563\n",
      "validation: 0.963 accuracy\n",
      "[34/48] training loss across clients 0.00348\n",
      "[ModelCheckpoint] New best model with 0.97060 validation accuracy\n",
      "[35/48] training loss across clients 0.00358\n",
      "validation: 0.967 accuracy\n",
      "[36/48] training loss across clients 0.00351\n",
      "validation: 0.970 accuracy\n",
      "[37/48] training loss across clients 0.00156\n",
      "validation: 0.969 accuracy\n",
      "[38/48] training loss across clients 0.00038\n",
      "validation: 0.966 accuracy\n",
      "[39/48] training loss across clients 0.00237\n",
      "validation: 0.967 accuracy\n",
      "[40/48] training loss across clients 0.00622\n",
      "validation: 0.969 accuracy\n",
      "[41/48] training loss across clients 0.00205\n",
      "validation: 0.967 accuracy\n",
      "[42/48] training loss across clients 0.00295\n",
      "validation: 0.967 accuracy\n",
      "[43/48] training loss across clients 0.00009\n",
      "validation: 0.966 accuracy\n",
      "[44/48] training loss across clients 0.00037\n",
      "validation: 0.968 accuracy\n",
      "[45/48] training loss across clients 0.00123\n",
      "validation: 0.968 accuracy\n",
      "[46/48] training loss across clients 0.00255\n",
      "validation: 0.964 accuracy\n",
      "[47/48] training loss across clients 0.00370\n",
      "validation: 0.967 accuracy\n",
      "[48/48] training loss across clients 0.00001\n",
      "validation: 0.968 accuracy\n"
     ]
    }
   ],
   "source": [
    "server = Server(clients)\n",
    "server.fit(optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The model quality improved from 70% to >97% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes \n",
    "\n",
    "Simplifications made:\n",
    "\n",
    "- All users sample from the same distribution\n",
    "- `ModelCheckpoint` cannot be based on validation data in the actual implementation\n",
    "- Users should run more than one SGD iteration locally\n",
    "\n",
    "## To make fitting easier\n",
    "\n",
    "- Fair initialization\n",
    "- Normalize data (0-center)\n",
    "- Remove features with a value of 0\n",
    "\n",
    "## Still missing\n",
    "\n",
    "- Implement frequency part (switch from one-hot encoding to up to sum of 10 and add multiplicative factor)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
