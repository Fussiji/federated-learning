{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecency Sampling\n",
    "\n",
    "To be able to quickly prototype the Federated Learning algorithm, a dataset is required.\n",
    "This notebook is based on a fake frecency dataset that was designed to be very interpretable and at the same time close to the actual data.\n",
    "The assumption for the data generation is that the current frecency algorithm is perfect. By sampling based on this axiom, we can check if the algorithm really finds the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:53.991384Z",
     "start_time": "2018-06-27T23:04:53.367694Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are weights that describe how common certain features are. For `recency` we assume a uniform distribution over time, for `type` numbers were chosen that intuitively seem to be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:54.602851Z",
     "start_time": "2018-06-27T23:04:54.596872Z"
    }
   },
   "outputs": [],
   "source": [
    "type_weights = {\n",
    "    \"visited\": 0.6,\n",
    "    \"typed\": 0.2,\n",
    "    \"bookmarked\": 0.2,\n",
    "    #\"other_type\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Actually there's also a feature `other_type` which has a weight of `0` in the original frecency algorithm, i.e. it's not really used. If we use this feature for this training process, it adds noise to the model because the model has not enough data to learn that this feature does not really add value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:55.469846Z",
     "start_time": "2018-06-27T23:04:55.463734Z"
    }
   },
   "outputs": [],
   "source": [
    "recency_weights = {\n",
    "    \"4-days\": 0.03,\n",
    "    \"14-days\": 0.05,\n",
    "    \"31-days\": 0.1,\n",
    "    \"90-days\": 0.32,\n",
    "    \"other_recency\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:55.826529Z",
     "start_time": "2018-06-27T23:04:55.821045Z"
    }
   },
   "outputs": [],
   "source": [
    "recency_weights = {\n",
    "    \"4-days\": 0.15,\n",
    "    \"14-days\": 0.15,\n",
    "    \"31-days\": 0.15,\n",
    "    \"90-days\": 0.2,\n",
    "    \"other_recency\": 0.35\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simulation, it seems to be a fair assumption that `type` and `recency` are independent of each other.\n",
    "This means we can just multiply the probabilities.\n",
    "\n",
    "This is probably not completely true, since users likely visit bookmarks more often, but it makes things easier here and the probabilities are hard to estimate well anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:56.631444Z",
     "start_time": "2018-06-27T23:04:56.622306Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_dicts_multiplicatively(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Returns a new dict where the keys consist of all pairs of keys from the input\n",
    "    dictionaries and the values correspond to the respective multiplied values.\n",
    "    \"\"\"\n",
    "    weights = {}\n",
    "\n",
    "    for key1, weight1 in dict1.items():\n",
    "        for key2, weight2 in dict2.items():\n",
    "            key = (key1, key2)\n",
    "            weight = weight1 * weight2\n",
    "            weights[key] = weight\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:57.008464Z",
     "start_time": "2018-06-27T23:04:57.003901Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = combine_dicts_multiplicatively(type_weights, recency_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-hot representation makes it easier to implement the rest of the formulas. numpy allows us to generate this easily using a permutation of the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:57.691721Z",
     "start_time": "2018-06-27T23:04:57.687097Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(num_choices, vector):\n",
    "    return np.eye(num_choices)[vector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input vector to the model is 20-dimensional: One field for every combination of `type` and `recency`.\n",
    "In the frecency algorithm, we consider the last ten visits to the URL.\n",
    "Thus, the sum of all elements of the vector is a natural number between 1 and 10.\n",
    "\n",
    "(Since `other-type` is commented out, it's only 15-dimensional for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:58.324366Z",
     "start_time": "2018-06-27T23:04:58.317565Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_weighted(num_samples, weight_dict):\n",
    "    \"\"\"Randomly sample from a dict using the values as probabilities\"\"\"\n",
    "    num_choices = len(weight_dict)\n",
    "    choice_weights = weight_dict.values()\n",
    "    samples = np.random.choice(num_choices, num_samples, p=choice_weights)\n",
    "    return one_hot(num_choices, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:58.709402Z",
     "start_time": "2018-06-27T23:04:58.705262Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_url_features(num_samples):\n",
    "    return sample_weighted(num_samples, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the target labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights found in the current frecency algorithm. Based on the one-hot encoding, this is just a linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:04:59.738724Z",
     "start_time": "2018-06-27T23:04:59.733337Z"
    }
   },
   "outputs": [],
   "source": [
    "type_points = {\n",
    "    \"visited\": 1.2,\n",
    "    \"typed\": 2,\n",
    "    \"bookmarked\": 1.4,\n",
    "    #\"other_type\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:00.194923Z",
     "start_time": "2018-06-27T23:05:00.189226Z"
    }
   },
   "outputs": [],
   "source": [
    "recency_points = {\n",
    "    \"4-days\": 100,\n",
    "    \"14-days\": 70,\n",
    "    \"31-days\": 50,\n",
    "    \"90-days\": 30,\n",
    "    \"other_recency\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:00.616682Z",
     "start_time": "2018-06-27T23:05:00.612524Z"
    }
   },
   "outputs": [],
   "source": [
    "frecency_points_dict = combine_dicts_multiplicatively(type_points, recency_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the order of keys is the same everywhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:01.402138Z",
     "start_time": "2018-06-27T23:05:01.397353Z"
    }
   },
   "outputs": [],
   "source": [
    "key_order = weights.keys()\n",
    "frecency_points = np.array([frecency_points_dict[key] for key in key_order])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the frecency points from the original algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:02.228196Z",
     "start_time": "2018-06-27T23:05:02.217946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('visited', '4-days'), 120.0),\n",
       " (('visited', '90-days'), 36.0),\n",
       " (('bookmarked', '14-days'), 98.0),\n",
       " (('bookmarked', 'other_recency'), 14.0),\n",
       " (('typed', 'other_recency'), 20.0),\n",
       " (('typed', '31-days'), 100.0),\n",
       " (('typed', '14-days'), 140.0),\n",
       " (('bookmarked', '31-days'), 70.0),\n",
       " (('typed', '4-days'), 200.0),\n",
       " (('bookmarked', '90-days'), 42.0),\n",
       " (('visited', '31-days'), 60.0),\n",
       " (('bookmarked', '4-days'), 140.0),\n",
       " (('visited', 'other_recency'), 12.0),\n",
       " (('typed', '90-days'), 60.0),\n",
       " (('visited', '14-days'), 84.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(key_order, frecency_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all these preparations, an arbitrary number of frecency scores can be computed using a single matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:02.931800Z",
     "start_time": "2018-06-27T23:05:02.926556Z"
    }
   },
   "outputs": [],
   "source": [
    "def frecency(url_features):\n",
    "    return url_features.dot(frecency_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are sampling from the above distributions and then call the frecency function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:03.607708Z",
     "start_time": "2018-06-27T23:05:03.602199Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(num_samples):\n",
    "    X = sample_url_features(num_samples)\n",
    "    y = frecency(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "This section is mostly to check that's it possible to fit a linear model perfectly to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:04.622318Z",
     "start_time": "2018-06-27T23:05:04.253716Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a model, we sample a lot of these scores and also add noise on top to make the problem more similar to the real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:05.384249Z",
     "start_time": "2018-06-27T23:05:05.082259Z"
    }
   },
   "outputs": [],
   "source": [
    "n = int(1e6)\n",
    "noise = np.random.normal(0, 2, size=(n))\n",
    "X, y = sample(n)\n",
    "y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:05.472424Z",
     "start_time": "2018-06-27T23:05:05.468651Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:06.720841Z",
     "start_time": "2018-06-27T23:05:05.928148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting coefficients are extremely close to the actual frecency weights. How close they are depends on how much noise we add to the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:07.367034Z",
     "start_time": "2018-06-27T23:05:07.358562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(119.99450275611275, 120.0),\n",
       " (36.00187452493747, 36.0),\n",
       " (98.017105541760188, 98.0),\n",
       " (13.997506622028792, 14.0),\n",
       " (19.999439513115139, 20.0),\n",
       " (100.01865303804851, 100.0),\n",
       " (139.99518259212479, 140.0),\n",
       " (70.004515720659469, 70.0),\n",
       " (200.00212307654931, 200.0),\n",
       " (41.997327683992573, 42.0),\n",
       " (59.998677212946042, 60.0),\n",
       " (139.99974359074812, 140.0),\n",
       " (12.002342390198455, 12.0),\n",
       " (60.008748077759869, 60.0),\n",
       " (84.007699562653812, 84.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(model.coef_, frecency_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:07.836269Z",
     "start_time": "2018-06-27T23:05:07.828917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00549724,  0.00187452,  0.01710554, -0.00249338, -0.00056049,\n",
       "        0.01865304, -0.00481741,  0.00451572,  0.00212308, -0.00267232,\n",
       "       -0.00132279, -0.00025641,  0.00234239,  0.00874808,  0.00769956])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ - frecency_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking\n",
    "\n",
    "Now, we make the problem slightly more difficult: Instead of just learning the frecency function from data, we try to learn it from user interactions. The training data now consists of a variable number of history suggestions and their respective features. The label corresponds to the suggestion that the user clicked on. We still assume that the user clicks on the item with the highest frecency score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:08.812857Z",
     "start_time": "2018-06-27T23:05:08.808960Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many suggestions match the search query is sampled from a normal distribution centered around `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:09.483037Z",
     "start_time": "2018-06-27T23:05:09.477429Z"
    }
   },
   "outputs": [],
   "source": [
    "num_options = np.random.normal(loc=10, scale=4, size=(n))\n",
    "num_options = np.maximum(num_options, 1)\n",
    "num_options = np.int32(num_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:10.094885Z",
     "start_time": "2018-06-27T23:05:09.872459Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f76e4db9f90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAF5CAYAAABN1yq9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76e5799fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(num_options)\n",
    "plt.xlabel(\"number of matches\")\n",
    "plt.ylabel(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:10.568825Z",
     "start_time": "2018-06-27T23:05:10.562993Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_num_options(n):\n",
    "    num_options = np.random.normal(loc=10, scale=4, size=(n))\n",
    "    num_options = np.maximum(num_options, 1)\n",
    "    return np.int32(num_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:10.816242Z",
     "start_time": "2018-06-27T23:05:10.810369Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_suggestions_normal(n):\n",
    "    num_options = sample_num_options(n)\n",
    "    data = map(sample, num_options)\n",
    "    X, y = zip(*data)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:12.840334Z",
     "start_time": "2018-06-27T23:05:12.833971Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_suggestions_spark(n):\n",
    "    num_options = sample_num_options(n)    \n",
    "    data = sc.parallelize(num_options).map(sample).collect()\n",
    "    X, y = zip(*data)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:13.377650Z",
     "start_time": "2018-06-27T23:05:13.372140Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_suggestions(n):\n",
    "    if n > 1000:\n",
    "        return sample_suggestions_spark(n)\n",
    "    else:\n",
    "        return sample_suggestions_normal(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Ranking\n",
    "\n",
    "After preparing the training data, we can try to use the adapted SVM loss (also called [hinge loss](https://en.wikipedia.org/wiki/Hinge_loss)) for ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:15.345145Z",
     "start_time": "2018-06-27T23:05:15.245061Z"
    }
   },
   "outputs": [],
   "source": [
    "n = int(1e3)\n",
    "X, y = sample_suggestions(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent generally works better when the data is centered around the origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:16.143636Z",
     "start_time": "2018-06-27T23:05:16.137393Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    X_flat = []\n",
    "\n",
    "    for x in X:\n",
    "        X_flat += list(x)\n",
    "\n",
    "    return np.array(X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:16.880027Z",
     "start_time": "2018-06-27T23:05:16.874732Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X_flat = flatten(X)\n",
    "    mu = X_flat.mean(axis=0)\n",
    "    return [x - mu for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:17.335210Z",
     "start_time": "2018-06-27T23:05:17.319531Z"
    }
   },
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer we use is fairly simple: It scales the gradient with a learning rate before adding it to the model.\n",
    "This abstraction as a class is still nice because we can later replace it with more sophisticated optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:18.555072Z",
     "start_time": "2018-06-27T23:05:18.548794Z"
    }
   },
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def __call__(self, gradient):\n",
    "        return self.learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:19.336229Z",
     "start_time": "2018-06-27T23:05:19.317056Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaptiveGradientDescent:\n",
    "    def __init__(self, learning_rate, num_features):\n",
    "        self.learning_rates = np.full(num_features, learning_rate)\n",
    "        self.min = 0.0000001\n",
    "        self.max = 50\n",
    "        self.a = 1.2\n",
    "        self.b = 0.5\n",
    "        \n",
    "        self.t = 0\n",
    "        self.last_gradient = None\n",
    "    \n",
    "    def __call__(self, gradient):\n",
    "        if self.t >= 1:\n",
    "            for i in range(len(gradient)):\n",
    "                if gradient[i] * self.last_gradient[i] > 0:\n",
    "                    self.learning_rates[i] = min(self.learning_rates[i] * self.a, self.max)\n",
    "                elif gradient[i] * self.last_gradient[i] < 0:\n",
    "                    self.learning_rates[i] = max(self.learning_rates[i] * self.b, self.min)\n",
    "            \n",
    "        self.t += 1\n",
    "        self.last_gradient = gradient\n",
    "        \n",
    "        return self.learning_rates * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T22:22:49.764693Z",
     "start_time": "2018-05-24T22:20:36.311Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecayedGradientDescent:\n",
    "    def __init__(self, learning_rate, decay):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def __call__(self, gradient):\n",
    "        result = self.learning_rate * gradient\n",
    "        \n",
    "        self.learning_rate = self.learning_rate * 1 / (1 + self.decay * self.epoch)\n",
    "        self.epoch += 1\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:19.912729Z",
     "start_time": "2018-06-27T23:05:19.894283Z"
    }
   },
   "outputs": [],
   "source": [
    "class RProp:\n",
    "    def __init__(self, learning_rate, num_features):\n",
    "        self.learning_rates = np.full(num_features, learning_rate)\n",
    "        self.min = 0.0000001\n",
    "        self.max = 50\n",
    "        self.a = 1.2\n",
    "        self.b = 0.5\n",
    "        \n",
    "        self.t = 0\n",
    "        self.last_gradient = None\n",
    "    \n",
    "    def __call__(self, gradient):\n",
    "        if self.t >= 1:\n",
    "            for i in range(len(gradient)):\n",
    "                if gradient[i] * self.last_gradient[i] > 0:\n",
    "                    self.learning_rates[i] = min(self.learning_rates[i] * self.a, self.max)\n",
    "                elif gradient[i] * self.last_gradient[i] < 0:\n",
    "                    self.learning_rates[i] = max(self.learning_rates[i] * self.b, self.min)\n",
    "            \n",
    "        self.t += 1\n",
    "        self.last_gradient = gradient\n",
    "        \n",
    "        return self.learning_rates * np.sign(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:20.577520Z",
     "start_time": "2018-06-27T23:05:20.553531Z"
    }
   },
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.alpha = 0.01\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "        self.t = 0\n",
    "        \n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.theta = None\n",
    "    \n",
    "    def __call__(self, gradient):\n",
    "        if self.t == 0:\n",
    "            self.m = np.zeros(gradient.shape)\n",
    "            self.v = np.zeros(gradient.shape)\n",
    "            self.theta = np.zeros(gradient.shape)\n",
    "        \n",
    "        self.t += 1\n",
    "        \n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * gradient**2\n",
    "        \n",
    "        m_corrected = self.m / (1 - self.beta1**self.t)\n",
    "        v_corrected = self.v / (1 - self.beta2**self.t)\n",
    "\n",
    "        self.theta += self.alpha * m_corrected / (np.sqrt(v_corrected) + self.eps)\n",
    "        \n",
    "        return self.learning_rate * self.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss (SVM loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To supervise training, we keep logging the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:21.569239Z",
     "start_time": "2018-06-27T23:05:21.561261Z"
    }
   },
   "outputs": [],
   "source": [
    "def svm_loss(preds, ys, delta=0):\n",
    "    correct = ys.argmax()\n",
    "    score_correct = preds[correct]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i, pred in enumerate(preds):\n",
    "        loss += max(0, pred + delta - score_correct)            \n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we want to supervise the learning process and save the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:22.314346Z",
     "start_time": "2018-06-27T23:05:22.300989Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelCheckpoint:\n",
    "    def __init__(self, metric_fn, num_sampled=10000):\n",
    "        self.best_model = None\n",
    "        self.best_metric = -np.inf\n",
    "        self.metric_fn = metric_fn\n",
    "        self.num_sampled = num_sampled\n",
    "    \n",
    "    def __call__(self, model):\n",
    "        X_val, y_val = sample_suggestions(self.num_sampled)\n",
    "        metric = self.metric_fn(y_val, model.predict(X_val))\n",
    "        \n",
    "        if metric > self.best_metric:\n",
    "            self.best_metric = metric\n",
    "            self.best_model = model\n",
    "            print(\"[ModelCheckpoint] New best model with %.5f validation accuracy\" % metric)\n",
    "        else:\n",
    "            print(\"validation: %.3f accuracy\" % metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy needs to be measured carefully here: In our simulation, we assume that the current frecency is the perfect ranking function. But because items sometimes get the same frecency scores, there can be more than one correct answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:23.048208Z",
     "start_time": "2018-06-27T23:05:23.040924Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_accuracy(y, preds):\n",
    "    correct = 0.\n",
    "    \n",
    "    for yi, pi in zip(y, preds):\n",
    "        if yi[pi.argmax()] == yi.max():\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SVMRanking` class is the main mechanism for fitting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:23.787432Z",
     "start_time": "2018-06-27T23:05:23.752446Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVMRanking:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "        \n",
    "    def fit(self, data_generator, optimizer, num_iterations=10, callbacks=[]):\n",
    "        X, y = data_generator(1)\n",
    "        num_features = X[0].shape[1]\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "        \n",
    "        for j in range(num_iterations):\n",
    "            X, y = data_generator(4000)\n",
    "            \n",
    "            preds = self.predict(X)\n",
    "            gradient = np.zeros(num_features)\n",
    "\n",
    "            for xi, pi, yi in zip(X, preds, y):\n",
    "                correct = yi.argmax()\n",
    "                score_correct = pi[correct]\n",
    "\n",
    "                for i, predicted_score in enumerate(pi):\n",
    "                    gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            gradient /= len(X)\n",
    "            \n",
    "            loss = np.mean([svm_loss(pi, yi) for pi, yi in zip(self.predict(X), y)])\n",
    "            accuracy = rank_accuracy(y, model.predict(X))\n",
    "            \n",
    "            print(\"[%d/%d] training: %.5f loss, %.3f accuracy\" % (j + 1, num_iterations, loss, accuracy))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:05:24.173107Z",
     "start_time": "2018-06-27T23:05:24.168334Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.cancelAllJobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:06:20.895532Z",
     "start_time": "2018-06-27T23:05:24.520185Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 16.98308 loss, 0.688 accuracy\n",
      "[ModelCheckpoint] New best model with 0.69900 validation accuracy\n",
      "[2/48] training: 4.57216 loss, 0.857 accuracy\n",
      "[ModelCheckpoint] New best model with 0.82330 validation accuracy\n",
      "[3/48] training: 2.79524 loss, 0.947 accuracy\n",
      "[ModelCheckpoint] New best model with 0.92540 validation accuracy\n",
      "[4/48] training: 2.90015 loss, 0.941 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94260 validation accuracy\n",
      "[5/48] training: 2.01631 loss, 0.944 accuracy\n",
      "validation: 0.942 accuracy\n",
      "[6/48] training: 2.14834 loss, 0.936 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94760 validation accuracy\n",
      "[7/48] training: 2.30280 loss, 0.933 accuracy\n",
      "validation: 0.939 accuracy\n",
      "[8/48] training: 1.34292 loss, 0.954 accuracy\n",
      "validation: 0.942 accuracy\n",
      "[9/48] training: 1.43061 loss, 0.941 accuracy\n",
      "validation: 0.943 accuracy\n",
      "[10/48] training: 1.29684 loss, 0.950 accuracy\n",
      "validation: 0.940 accuracy\n",
      "[11/48] training: 1.41823 loss, 0.944 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95160 validation accuracy\n",
      "[12/48] training: 1.04449 loss, 0.949 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95830 validation accuracy\n",
      "[13/48] training: 1.03664 loss, 0.943 accuracy\n",
      "validation: 0.950 accuracy\n",
      "[14/48] training: 1.00894 loss, 0.952 accuracy\n",
      "validation: 0.946 accuracy\n",
      "[15/48] training: 0.87711 loss, 0.951 accuracy\n",
      "validation: 0.953 accuracy\n",
      "[16/48] training: 0.76070 loss, 0.959 accuracy\n",
      "validation: 0.951 accuracy\n",
      "[17/48] training: 1.01407 loss, 0.941 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[18/48] training: 0.56162 loss, 0.952 accuracy\n",
      "validation: 0.954 accuracy\n",
      "[19/48] training: 0.46108 loss, 0.958 accuracy\n",
      "validation: 0.949 accuracy\n",
      "[20/48] training: 0.52120 loss, 0.956 accuracy\n",
      "validation: 0.955 accuracy\n",
      "[21/48] training: 0.43030 loss, 0.951 accuracy\n",
      "validation: 0.954 accuracy\n",
      "[22/48] training: 0.42244 loss, 0.952 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95910 validation accuracy\n",
      "[23/48] training: 0.41654 loss, 0.957 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96070 validation accuracy\n",
      "[24/48] training: 0.48611 loss, 0.959 accuracy\n",
      "validation: 0.959 accuracy\n",
      "[25/48] training: 0.30972 loss, 0.965 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[26/48] training: 0.42625 loss, 0.956 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96130 validation accuracy\n",
      "[27/48] training: 0.39848 loss, 0.958 accuracy\n",
      "validation: 0.957 accuracy\n",
      "[28/48] training: 0.26810 loss, 0.955 accuracy\n",
      "validation: 0.951 accuracy\n",
      "[29/48] training: 0.37086 loss, 0.946 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[30/48] training: 0.41172 loss, 0.952 accuracy\n",
      "validation: 0.956 accuracy\n",
      "[31/48] training: 0.32189 loss, 0.949 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[32/48] training: 0.31921 loss, 0.951 accuracy\n",
      "validation: 0.949 accuracy\n",
      "[33/48] training: 0.49757 loss, 0.951 accuracy\n",
      "validation: 0.949 accuracy\n",
      "[34/48] training: 0.24398 loss, 0.954 accuracy\n",
      "validation: 0.948 accuracy\n",
      "[35/48] training: 0.29974 loss, 0.955 accuracy\n",
      "validation: 0.950 accuracy\n",
      "[36/48] training: 0.29375 loss, 0.950 accuracy\n",
      "validation: 0.949 accuracy\n",
      "[37/48] training: 0.29905 loss, 0.948 accuracy\n",
      "validation: 0.953 accuracy\n",
      "[38/48] training: 0.22184 loss, 0.962 accuracy\n",
      "validation: 0.950 accuracy\n",
      "[39/48] training: 0.34377 loss, 0.949 accuracy\n",
      "validation: 0.957 accuracy\n",
      "[40/48] training: 0.14915 loss, 0.956 accuracy\n",
      "validation: 0.956 accuracy\n",
      "[41/48] training: 0.14109 loss, 0.953 accuracy\n",
      "validation: 0.953 accuracy\n",
      "[42/48] training: 0.16126 loss, 0.949 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[43/48] training: 0.17824 loss, 0.955 accuracy\n",
      "validation: 0.952 accuracy\n",
      "[44/48] training: 0.12180 loss, 0.957 accuracy\n",
      "validation: 0.949 accuracy\n",
      "[45/48] training: 0.17479 loss, 0.945 accuracy\n",
      "validation: 0.946 accuracy\n",
      "[46/48] training: 0.23576 loss, 0.941 accuracy\n",
      "validation: 0.955 accuracy\n",
      "[47/48] training: 0.15302 loss, 0.947 accuracy\n",
      "validation: 0.937 accuracy\n",
      "[48/48] training: 0.27985 loss, 0.944 accuracy\n",
      "validation: 0.946 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(5.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:06:20.902783Z",
     "start_time": "2018-06-27T23:06:20.898523Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.cancelAllJobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:06:21.127994Z",
     "start_time": "2018-06-27T23:06:20.905135Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-90b34a88a3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "opt.learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T21:47:35.395570Z",
     "start_time": "2018-05-29T21:46:49.525678Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 14.53182 loss, 0.704 accuracy\n",
      "[ModelCheckpoint] New best model with 0.70440 validation accuracy\n",
      "[2/48] training: 13.82159 loss, 0.711 accuracy\n",
      "[ModelCheckpoint] New best model with 0.71590 validation accuracy\n",
      "[3/48] training: 12.81232 loss, 0.725 accuracy\n",
      "validation: 0.707 accuracy\n",
      "[4/48] training: 13.40554 loss, 0.699 accuracy\n",
      "validation: 0.694 accuracy\n",
      "[5/48] training: 13.91462 loss, 0.814 accuracy\n",
      "[ModelCheckpoint] New best model with 0.80910 validation accuracy\n",
      "[6/48] training: 14.09351 loss, 0.798 accuracy\n",
      "validation: 0.802 accuracy\n",
      "[7/48] training: 13.62969 loss, 0.802 accuracy\n",
      "validation: 0.804 accuracy\n",
      "[8/48] training: 13.10961 loss, 0.807 accuracy\n",
      "validation: 0.803 accuracy\n",
      "[9/48] training: 12.91363 loss, 0.805 accuracy\n",
      "validation: 0.799 accuracy\n",
      "[10/48] training: 11.21521 loss, 0.806 accuracy\n",
      "validation: 0.797 accuracy\n",
      "[11/48] training: 11.19392 loss, 0.794 accuracy\n",
      "[ModelCheckpoint] New best model with 0.81470 validation accuracy\n",
      "[12/48] training: 9.33306 loss, 0.818 accuracy\n",
      "[ModelCheckpoint] New best model with 0.81700 validation accuracy\n",
      "[13/48] training: 8.78348 loss, 0.813 accuracy\n",
      "[ModelCheckpoint] New best model with 0.81800 validation accuracy\n",
      "[14/48] training: 7.72257 loss, 0.824 accuracy\n",
      "validation: 0.808 accuracy\n",
      "[15/48] training: 6.74545 loss, 0.812 accuracy\n",
      "validation: 0.809 accuracy\n",
      "[16/48] training: 6.37328 loss, 0.802 accuracy\n",
      "validation: 0.814 accuracy\n",
      "[17/48] training: 5.92561 loss, 0.816 accuracy\n",
      "[ModelCheckpoint] New best model with 0.82540 validation accuracy\n",
      "[18/48] training: 4.23934 loss, 0.836 accuracy\n",
      "[ModelCheckpoint] New best model with 0.83680 validation accuracy\n",
      "[19/48] training: 3.87281 loss, 0.834 accuracy\n",
      "validation: 0.829 accuracy\n",
      "[20/48] training: 3.20311 loss, 0.849 accuracy\n",
      "[ModelCheckpoint] New best model with 0.83790 validation accuracy\n",
      "[21/48] training: 2.98336 loss, 0.848 accuracy\n",
      "[ModelCheckpoint] New best model with 0.83900 validation accuracy\n",
      "[22/48] training: 2.61798 loss, 0.849 accuracy\n",
      "validation: 0.838 accuracy\n",
      "[23/48] training: 1.82567 loss, 0.847 accuracy\n",
      "[ModelCheckpoint] New best model with 0.84520 validation accuracy\n",
      "[24/48] training: 1.76045 loss, 0.846 accuracy\n",
      "validation: 0.841 accuracy\n",
      "[25/48] training: 1.49437 loss, 0.946 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94250 validation accuracy\n",
      "[26/48] training: 1.40226 loss, 0.942 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94320 validation accuracy\n",
      "[27/48] training: 1.04099 loss, 0.944 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94410 validation accuracy\n",
      "[28/48] training: 0.74904 loss, 0.957 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95410 validation accuracy\n",
      "[29/48] training: 0.54490 loss, 0.951 accuracy\n",
      "validation: 0.953 accuracy\n",
      "[30/48] training: 0.44752 loss, 0.955 accuracy\n",
      "validation: 0.947 accuracy\n",
      "[31/48] training: 0.43718 loss, 0.957 accuracy\n",
      "validation: 0.950 accuracy\n",
      "[32/48] training: 0.51906 loss, 0.954 accuracy\n",
      "validation: 0.950 accuracy\n",
      "[33/48] training: 0.27420 loss, 0.893 accuracy\n",
      "validation: 0.889 accuracy\n",
      "[34/48] training: 0.17773 loss, 0.892 accuracy\n",
      "validation: 0.889 accuracy\n",
      "[35/48] training: 0.12814 loss, 0.974 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97030 validation accuracy\n",
      "[36/48] training: 0.12420 loss, 0.972 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[37/48] training: 0.09589 loss, 0.970 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97130 validation accuracy\n",
      "[38/48] training: 0.03962 loss, 0.968 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97460 validation accuracy\n",
      "[39/48] training: 0.02577 loss, 0.969 accuracy\n",
      "validation: 0.971 accuracy\n",
      "[40/48] training: 0.03293 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[41/48] training: 0.02011 loss, 0.969 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[42/48] training: 0.01286 loss, 0.964 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[43/48] training: 0.01583 loss, 0.968 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[44/48] training: 0.03779 loss, 0.967 accuracy\n",
      "validation: 0.969 accuracy\n",
      "[45/48] training: 0.01039 loss, 0.975 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[46/48] training: 0.01832 loss, 0.971 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[47/48] training: 0.01932 loss, 0.972 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[48/48] training: 0.00783 loss, 0.967 accuracy\n",
      "validation: 0.970 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "opt = AdaptiveGradientDescent(0.1, len(frecency_points))\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=opt,\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T18:29:58.142049Z",
     "start_time": "2018-05-29T18:29:32.752195Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 3.79408 loss, 0.843 accuracy\n",
      "[ModelCheckpoint] New best model with 0.84360 validation accuracy\n",
      "[2/48] training: 2.67392 loss, 0.935 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96540 validation accuracy\n",
      "[3/48] training: 0.73219 loss, 0.983 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97990 validation accuracy\n",
      "[4/48] training: 1.07223 loss, 0.958 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98100 validation accuracy\n",
      "[5/48] training: 0.74734 loss, 0.965 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[6/48] training: 0.25034 loss, 0.973 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[7/48] training: 0.24616 loss, 0.968 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[8/48] training: 0.13096 loss, 0.985 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[9/48] training: 0.23453 loss, 0.970 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98130 validation accuracy\n",
      "[10/48] training: 0.15009 loss, 0.975 accuracy\n",
      "[ModelCheckpoint] New best model with 0.98370 validation accuracy\n",
      "[11/48] training: 0.04461 loss, 0.985 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[12/48] training: 0.17590 loss, 0.983 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[13/48] training: 0.10473 loss, 0.970 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[14/48] training: 0.07683 loss, 0.983 accuracy\n",
      "validation: 0.980 accuracy\n",
      "[15/48] training: 0.01459 loss, 0.983 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[16/48] training: 0.05169 loss, 0.975 accuracy\n",
      "validation: 0.981 accuracy\n",
      "[17/48] training: 0.06215 loss, 0.963 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[18/48] training: 0.03832 loss, 0.983 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[19/48] training: 0.01268 loss, 0.970 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[20/48] training: 0.03030 loss, 0.978 accuracy\n",
      "validation: 0.982 accuracy\n",
      "[21/48] training: 0.01398 loss, 0.965 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[22/48] training: 0.00374 loss, 1.000 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99320 validation accuracy\n",
      "[23/48] training: 0.02217 loss, 0.993 accuracy\n",
      "validation: 0.991 accuracy\n",
      "[24/48] training: 0.00664 loss, 0.990 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[25/48] training: 0.01731 loss, 0.988 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99480 validation accuracy\n",
      "[26/48] training: 0.01764 loss, 0.988 accuracy\n",
      "validation: 0.990 accuracy\n",
      "[27/48] training: 0.01019 loss, 0.990 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[28/48] training: 0.01701 loss, 0.988 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[29/48] training: 0.00452 loss, 0.993 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[30/48] training: 0.00286 loss, 0.988 accuracy\n",
      "validation: 0.994 accuracy\n",
      "[31/48] training: 0.00446 loss, 0.990 accuracy\n",
      "validation: 0.995 accuracy\n",
      "[32/48] training: 0.00714 loss, 0.985 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[33/48] training: 0.00128 loss, 0.995 accuracy\n",
      "validation: 0.992 accuracy\n",
      "[34/48] training: 0.00123 loss, 0.988 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[35/48] training: 0.00422 loss, 0.985 accuracy\n",
      "validation: 0.994 accuracy\n",
      "[36/48] training: 0.00163 loss, 0.998 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99500 validation accuracy\n",
      "[37/48] training: 0.00195 loss, 0.985 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[38/48] training: 0.00261 loss, 0.978 accuracy\n",
      "validation: 0.994 accuracy\n",
      "[39/48] training: 0.00115 loss, 0.993 accuracy\n",
      "validation: 0.991 accuracy\n",
      "[40/48] training: 0.00001 loss, 0.988 accuracy\n",
      "validation: 0.991 accuracy\n",
      "[41/48] training: 0.00334 loss, 0.983 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[42/48] training: 0.00132 loss, 0.995 accuracy\n",
      "validation: 0.993 accuracy\n",
      "[43/48] training: 0.00379 loss, 0.990 accuracy\n",
      "validation: 0.992 accuracy\n",
      "[44/48] training: 0.00108 loss, 0.990 accuracy\n",
      "validation: 0.990 accuracy\n",
      "[45/48] training: 0.00381 loss, 0.990 accuracy\n",
      "validation: 0.994 accuracy\n",
      "[46/48] training: 0.00157 loss, 0.988 accuracy\n",
      "validation: 0.994 accuracy\n",
      "[47/48] training: 0.00054 loss, 0.995 accuracy\n",
      "validation: 0.994 accuracy\n",
      "[48/48] training: 0.00120 loss, 0.990 accuracy\n",
      "validation: 0.992 accuracy\n"
     ]
    }
   ],
   "source": [
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can compare the learned weights with the true frecency scores. Note that the values themselves are very different now but that the ordering is nearly the same as in the real algorithm. This shows that we are ranking very similarly to the real algorithm but that the optimization process did not fully reach the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T21:44:05.901624Z",
     "start_time": "2018-05-29T21:44:05.892455Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, -194.00287105657827),\n",
       " (14.0, -183.5343037747067),\n",
       " (20.0, -195.48519437135437),\n",
       " (36.0, -177.79262977672352),\n",
       " (42.0, -172.11116782499278),\n",
       " (60.0, -162.86180600094758),\n",
       " (60.0, -164.76096677834511),\n",
       " (70.0, -152.9487800590953),\n",
       " (84.0, -150.73862111313508),\n",
       " (98.0, -133.73860757832759),\n",
       " (100.0, -145.41575741310663),\n",
       " (120.0, -131.52710517531798),\n",
       " (140.0, -119.60629786724751),\n",
       " (140.0, -130.76203878953726),\n",
       " (200.0, 244.46689170495839)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais = np.argsort(frecency_points)\n",
    "zip(frecency_points[ais], model.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, the model is correct most of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T00:13:25.606717Z",
     "start_time": "2018-05-25T00:13:24.958133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = sample_suggestions(10000)\n",
    "rank_accuracy(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: Evaluation during training in production\n",
    "\n",
    "If we only use 400 data points for validating the current model, then this is not enough to properly assess the model quality.\n",
    "The accuracies jump too much.\n",
    "However, this evaluation could still be used to test that the model is not completely off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T00:19:34.500115Z",
     "start_time": "2018-05-25T00:19:26.956763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   4.,   11.,   47.,   65.,  109.,  286.,  163.,  247.,   51.,   16.]),\n",
       " array([ 0.965 ,  0.9685,  0.972 ,  0.9755,  0.979 ,  0.9825,  0.986 ,\n",
       "         0.9895,  0.993 ,  0.9965,  1.    ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFkCAYAAACNTikJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiQV8f8BiropJhLaGj4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b7f9b1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = sample_suggestions(1000 * 400)\n",
    "accuracies = []\n",
    "\n",
    "for i in range(0, len(X) - 400, 400):\n",
    "    Xi, yi = X[i:i+400], y[i:i+400]\n",
    "    acc = rank_accuracy(yi, model.predict(Xi))\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "plt.hist(sorted(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency\n",
    "\n",
    "We still need to take into account that users visit links more than once.\n",
    "How often a user visits a link is sampled from an exponential distribution in this simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T00:20:03.967263Z",
     "start_time": "2018-05-25T00:20:03.732006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 493.,  229.,  143.,   68.,   33.,   15.,    7.,    8.,    2.,    2.]),\n",
       " array([  0. ,   4.4,   8.8,  13.2,  17.6,  22. ,  26.4,  30.8,  35.2,\n",
       "         39.6,  44. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRV+3/r7f4zNZ4YpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b79e93a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequencies = np.int32(np.random.exponential(7, size=(1000)))\n",
    "plt.hist(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T00:20:04.550404Z",
     "start_time": "2018-05-25T00:20:04.539093Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_url_features(num_samples):\n",
    "    frequencies = np.int32(np.random.exponential(7, size=num_samples)) + 1\n",
    "    frequencies = np.int32(np.ones(num_samples))\n",
    "    X = []\n",
    "    \n",
    "    for frequency in frequencies:\n",
    "        num_sampled = min(10, frequency)\n",
    "        features = sample_weighted(num_sampled, weights).sum(axis=0)\n",
    "        X.append(frequency / num_sampled * features)\n",
    "        \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T00:20:59.541257Z",
     "start_time": "2018-05-25T00:20:05.951881Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 6.68685 loss, 0.838 accuracy\n",
      "[ModelCheckpoint] New best model with 0.84440 validation accuracy\n",
      "[2/48] training: 0.99414 loss, 0.950 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96520 validation accuracy\n",
      "[3/48] training: 0.69720 loss, 0.973 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97010 validation accuracy\n",
      "[4/48] training: 0.31055 loss, 0.973 accuracy\n",
      "validation: 0.969 accuracy\n",
      "[5/48] training: 0.13849 loss, 0.968 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[6/48] training: 0.11023 loss, 0.973 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[7/48] training: 0.10748 loss, 0.975 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97050 validation accuracy\n",
      "[8/48] training: 0.03272 loss, 0.975 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97330 validation accuracy\n",
      "[9/48] training: 0.15880 loss, 0.973 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[10/48] training: 0.08625 loss, 0.975 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97420 validation accuracy\n",
      "[11/48] training: 0.02461 loss, 0.975 accuracy\n",
      "validation: 0.971 accuracy\n",
      "[12/48] training: 0.00085 loss, 0.978 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97450 validation accuracy\n",
      "[13/48] training: 0.08425 loss, 0.968 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97670 validation accuracy\n",
      "[14/48] training: 0.02949 loss, 0.970 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[15/48] training: 0.01767 loss, 0.973 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[16/48] training: 0.01378 loss, 0.965 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[17/48] training: 0.04177 loss, 0.983 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[18/48] training: 0.08431 loss, 0.973 accuracy\n",
      "validation: 0.971 accuracy\n",
      "[19/48] training: 0.01428 loss, 0.980 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[20/48] training: 0.02923 loss, 0.975 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[21/48] training: 0.00978 loss, 0.970 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[22/48] training: 0.00724 loss, 0.985 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[23/48] training: 0.04515 loss, 0.983 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[24/48] training: 0.02568 loss, 0.980 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[25/48] training: 0.00276 loss, 0.968 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[26/48] training: 0.00947 loss, 0.978 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[27/48] training: 0.00876 loss, 0.995 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[28/48] training: 0.00122 loss, 0.985 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[29/48] training: 0.00414 loss, 0.990 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[30/48] training: 0.01561 loss, 0.970 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[31/48] training: 0.01226 loss, 0.980 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[32/48] training: 0.01767 loss, 0.963 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97770 validation accuracy\n",
      "[33/48] training: 0.00059 loss, 0.980 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[34/48] training: 0.01380 loss, 0.968 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[35/48] training: 0.00363 loss, 0.958 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97800 validation accuracy\n",
      "[36/48] training: 0.00018 loss, 0.973 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[37/48] training: 0.00000 loss, 0.978 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[38/48] training: 0.00583 loss, 0.978 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[39/48] training: 0.00011 loss, 0.983 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[40/48] training: 0.00327 loss, 0.975 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[41/48] training: 0.00605 loss, 0.970 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[42/48] training: 0.00008 loss, 0.965 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[43/48] training: 0.00004 loss, 0.988 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[44/48] training: 0.00000 loss, 0.988 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[45/48] training: 0.01262 loss, 0.978 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[46/48] training: 0.00209 loss, 0.980 accuracy\n",
      "validation: 0.974 accuracy\n",
      "[47/48] training: 0.00272 loss, 0.973 accuracy\n",
      "validation: 0.972 accuracy\n",
      "[48/48] training: 0.00004 loss, 0.975 accuracy\n",
      "validation: 0.975 accuracy\n"
     ]
    }
   ],
   "source": [
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, 10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning\n",
    "\n",
    "To implement a federated version of the model above, we have to create a `Client` class that completely encapsulates training data. Only the `Client` can compute gradients based on its own data. While the `Server` is the main class for controlling the training process, it can only request gradients from clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:07:40.264336Z",
     "start_time": "2018-06-27T23:07:40.259984Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:07:40.783445Z",
     "start_time": "2018-06-27T23:07:40.757281Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        \n",
    "        num_features = len(frecency_points)\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "    \n",
    "    def fit(self, optimizer, num_iterations, num_clients_per_iteration, callbacks=[]):\n",
    "        for j in range(num_iterations):\n",
    "            clients = random.sample(self.clients, num_clients_per_iteration)\n",
    "            updates, losses = zip(*[client.request_update(self) for client in clients])\n",
    "            \n",
    "            gradient = np.mean(updates, axis=0)\n",
    "            loss = np.mean(losses, axis=0)\n",
    "            \n",
    "            print(\"[%d/%d] training loss across clients %.5f\" % (j + 1, num_iterations, loss))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:07:41.893645Z",
     "start_time": "2018-06-27T23:07:41.873075Z"
    }
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model):\n",
    "        X, y = self.data_generator()\n",
    "        preds = model.predict(X)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = np.zeros(num_features)\n",
    "        loss = 0\n",
    "\n",
    "        for xi, pi, yi in zip(X, preds, y):\n",
    "            correct = yi.argmax()\n",
    "            score_correct = pi[correct]\n",
    "\n",
    "            for i, predicted_score in enumerate(pi):\n",
    "                gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            loss += svm_loss(pi, yi)\n",
    "                \n",
    "        gradient /= len(X)\n",
    "        loss /= len(X)\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many data points a user has in each round is sampled from the following exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:07:42.906600Z",
     "start_time": "2018-06-27T23:07:42.677732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 716.,    0.,  202.,    0.,   55.,    0.,   21.,    0.,    5.,    1.]),\n",
       " array([ 1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,  6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAHMZJREFUeJzt3X+sXOV95/H3h4JNSWMjhWKHpt4S0bquUtH1pSYoDdld\nsqQENSVL1XKbLAuIsiSAqLdSSVSquljbzRIVvKROhbSo+UFyI6/ZiIZSKCUtJYZghUtJ0ziuaEwd\nQuzmJuzFMgEH+O4fc5yOpw+GGV97Lvb7JY2485zvnPs9I+T53Oc8Z06qCkmSpEFHjbsBSZI0PxkS\nJElSkyFBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVLTUCEhyVFJ1ib5\nepJnkjyW5NpG3XVJnuxq7klyysD2hUnWJ5lJsivJxiQnHujBSJKkuTPsTMIHgP8KvB/4aeC3gd9O\ncuXegiTXAFcClwGrgN3A3UkW9O1nHXAucD5wJnAScNuIxyBJkg6CDHODpySfA3ZU1W/0jW0Enqmq\nC7vnTwIfrqobu+eLgJ3Af6mqDd3zbwMXVNVnu5rlwBbgzVW1eW4OTZIkHYhhZxIeAM5K8pMASU4F\n3gLc2T0/GVgK3Lv3BVX1NPAQcEY3dBpw9EDNVmB7X40kSRqzo4es/xCwCPhakhfohYzfqarPdNuX\nAkVv5qDfzm4bwBJgTxceXqpmH0leB7wDeBx4dsieJUk6kh0L/ARwd1V9Z5gXDhsSfg34deAC4KvA\nzwH/K8mTVfXJIfc1jHcAnzqI+5ck6XD3HuDTw7xg2JBwPfA/qur/dM//PslPAB8EPgnsAEJvtqB/\nNmEJ8Ej38w5gQZJFA7MJS7ptLY8D3HrrraxYsWLIljWq1atXc+ONN467jSOK7/mh53t+6PmeH1pb\ntmzhve99L3SfpcMYNiQcB7wwMPYi3dqGqtqWZAdwFvBl+MHCxdOB9V39w8DzXU3/wsVlwIMv8Xuf\nBVixYgUrV64csmWNavHixb7fh5jv+aHne37o+Z6PzdCn64cNCZ8Drk3yBPD3wEpgNfC/+2rWdTWP\n0Usta4EngNuht5AxyS3ADUmeAnYBNwGbvLJBkqT5Y9iQcCW9D/31wInAk8Afd2MAVNX1SY4DbgaO\nB+4HzqmqPX37WU1vRmIjsBC4C7hixGOQJEkHwVAhoap2A/+te+yvbg2wZj/bnwOu6h6SJGke8t4N\nekmTk5PjbuGI43t+6PmeH3q+568eQ33j4rgkWQk8/PDDD7vYRZKkIUxPTzMxMQEwUVXTw7zWmQRJ\nktRkSJAkSU2GBEmS1GRIkCRJTYYESZLUZEiQJElNhgRJktRkSJAkSU2GBEmS1GRIkCRJTYYESZLU\nZEiQJElNhgRJktRkSJAkSU2GBEmS1GRIkCRJTYYESZLUZEiQJElNhgRJktRkSJAkSU2GBEmS1GRI\nkCRJTYYESZLUZEiQJElNR4+7gWH85m/+JosXLx53G0N57Wtfy0c+8hFe97rXjbsVSZKG8qoKCfff\nfxTwQ+NuYwgvAlOcffbZXHTRReNuRpKkoQwVEpJsA/5NY9P6qrqqq7kOuBQ4HtgEvK+qHuvbx0Lg\nBuDXgIXA3cD7q+qfX76DG4CVw7Q8Zs8Dx4y7CUmSRjLsmoTTgKV9j/8IFLABIMk1wJXAZcAqYDdw\nd5IFfftYB5wLnA+cCZwE3Db6IUiSpINhqJmEqvpO//MkvwT8Y1Xd3w1dDaytqju67RcCO4HzgA1J\nFgGXABdU1X1dzcXAliSrqmrzAR2NJEmaMyNf3ZDkGOA9wC3d85PpzS7cu7emqp4GHgLO6IZOoxdM\n+mu2Atv7aiRJ0jxwIJdAvhtYDHy8e76U3qmHnQN1O7ttAEuAPV14eKkaSZI0DxzI1Q2XAH9eVTvm\nqpmXt5peLuk32T0kSTqyTU1NMTU1tc/Y7OzsyPsbKSQkWQa8nd5ag712AKE3W9A/m7AEeKSvZkGS\nRQOzCUu6bS/jRl5dVzdIknToTE5OMjm57x/O09PTTExMjLS/UU83XEIvCNy5d6CqttH7oD9r71i3\nUPF04IFu6GF61wX21ywHlgEPjtiLJEk6CIaeSUgS4CLgY1X14sDmdcC1SR4DHgfWAk8At0NvIWOS\nW4AbkjwF7AJuAjZ5ZYMkSfPLKKcb3g78OPAngxuq6vokxwE30/sypfuBc6pqT1/ZauAFYCO9L1O6\nC7hihD4kSdJBNHRIqKp72M93I1fVGmDNfrY/B1zVPSRJ0jzlXSAlSVKTIUGSJDUZEiRJUpMhQZIk\nNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZ\nEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIk\nSVKTIUGSJDUZEiRJUpMhQZIkNQ0dEpKclOSTSWaSPJPk0SQrB2quS/Jkt/2eJKcMbF+YZH23j11J\nNiY58UAPRpIkzZ2hQkKS44FNwHPAO4AVwG8BT/XVXANcCVwGrAJ2A3cnWdC3q3XAucD5wJnAScBt\nIx+FJEmac0cPWf8BYHtVXdo39k8DNVcDa6vqDoAkFwI7gfOADUkWAZcAF1TVfV3NxcCWJKuqavMI\nxyFJkubYsKcbfgn4UpINSXYmmU7yg8CQ5GRgKXDv3rGqehp4CDijGzqNXjjpr9kKbO+rkSRJYzZs\nSHgj8D5gK3A28MfATUn+c7d9KVD0Zg767ey2ASwB9nTh4aVqJEnSmA17uuEoYHNV/W73/NEkbwIu\nBz45p501rQYWD4xNdg9Jko5sU1NTTE1N7TM2Ozs78v6GDQnfArYMjG0B/lP38w4g9GYL+mcTlgCP\n9NUsSLJoYDZhSbdtP24EVu6/RJKkI9Tk5CSTk/v+4Tw9Pc3ExMRI+xv2dMMmYPnA2HK6xYtVtY3e\nB/1Zezd2CxVPBx7ohh4Gnh+oWQ4sAx4csh9JknSQDDuTcCOwKckHgQ30PvwvBX6jr2YdcG2Sx4DH\ngbXAE8Dt0FvImOQW4IYkTwG7gJuATV7ZIEnS/DFUSKiqLyV5N/Ah4HeBbcDVVfWZvprrkxwH3Awc\nD9wPnFNVe/p2tRp4AdgILATuAq44kAORJElza9iZBKrqTuDOl6lZA6zZz/bngKu6hyRJmoe8d4Mk\nSWoyJEiSpCZDgiRJajIkSJKkJkOCJElqMiRIkqQmQ4IkSWoyJEiSpCZDgiRJajIkSJKkJkOCJElq\nMiRIkqQmQ4IkSWoyJEiSpCZDgiRJajIkSJKkJkOCJElqMiRIkqQmQ4IkSWoyJEiSpCZDgiRJajIk\nSJKkJkOCJElqMiRIkqQmQ4IkSWoyJEiSpCZDgiRJahoqJCT5vSQvDjy+OlBzXZInkzyT5J4kpwxs\nX5hkfZKZJLuSbExy4lwcjCRJmjujzCR8BVgCLO0ev7B3Q5JrgCuBy4BVwG7g7iQL+l6/DjgXOB84\nEzgJuG2U5iVJ0sFz9Aiveb6qvv0S264G1lbVHQBJLgR2AucBG5IsAi4BLqiq+7qai4EtSVZV1eYR\n+pEkSQfBKDMJP5nkm0n+McmtSX4cIMnJ9GYW7t1bWFVPAw8BZ3RDp9ELJv01W4HtfTWSJGkeGDYk\nfBG4CHgHcDlwMvA3SV5DLyAUvZmDfju7bdA7TbGnCw8vVSNJkuaBoU43VNXdfU+/kmQz8E/ArwJf\nm8vGJEnSeI2yJuEHqmo2yT8ApwB/DYTebEH/bMIS4JHu5x3AgiSLBmYTlnTbXsZqYPHA2GT3kCTp\nyDY1NcXU1NQ+Y7OzsyPv74BCQpIfoRcQPl5V25LsAM4CvtxtXwScDqzvXvIw8HxX89muZjmwDHjw\n5X/jjcDKA2lZkqTD1uTkJJOT+/7hPD09zcTExEj7GyokJPkw8Dl6pxh+DPh94PvAZ7qSdcC1SR4D\nHgfWAk8At0NvIWOSW4AbkjwF7AJuAjZ5ZYMkSfPLsDMJbwA+DbwO+DbwBeDNVfUdgKq6PslxwM3A\n8cD9wDlVtadvH6uBF4CNwELgLuCKAzkISZI094ZduPiyJ/+rag2wZj/bnwOu6h6SJGme8t4NkiSp\nyZAgSZKaDAmSJKnJkCBJkpoMCZIkqcmQIEmSmgwJkiSpyZAgSZKaDAmSJKnJkCBJkpoMCZIkqcmQ\nIEmSmgwJkiSpyZAgSZKaDAmSJKnJkCBJkpoMCZIkqcmQIEmSmgwJkiSpyZAgSZKaDAmSJKnJkCBJ\nkpoMCZIkqcmQIEmSmgwJkiSpyZAgSZKaDAmSJKnJkCBJkpoOKCQk+UCSF5PcMDB+XZInkzyT5J4k\npwxsX5hkfZKZJLuSbExy4oH0IkmS5tbIISHJzwOXAY8OjF8DXNltWwXsBu5OsqCvbB1wLnA+cCZw\nEnDbqL1IkqS5N1JISPIjwK3ApcD/G9h8NbC2qu6oqq8AF9ILAed1r10EXAKsrqr7quoR4GLgLUlW\njXYYkiRpro06k7Ae+FxVfb5/MMnJwFLg3r1jVfU08BBwRjd0GnD0QM1WYHtfjSRJGrOjh31BkguA\nn6P3YT9oKVDAzoHxnd02gCXAni48vFSNJEkas6FCQpI30FtP8Paq+v7BaWl/VgOLB8Ymu4ckSUe2\nqakppqam9hmbnZ0deX/DziRMAD8KTCdJN/ZDwJlJrgR+Ggi92YL+2YQlwCPdzzuABUkWDcwmLOm2\n7ceNwMohW5Yk6cgwOTnJ5OS+fzhPT08zMTEx0v6GXZPwl8DP0jvdcGr3+BK9RYynVtXX6X3Qn7X3\nBd1CxdOBB7qhh4HnB2qWA8uAB0c6CkmSNOeGmkmoqt3AV/vHkuwGvlNVW7qhdcC1SR4DHgfWAk8A\nt3f7eDrJLcANSZ4CdgE3AZuqavMBHIskSZpDQy9cbKh9nlRdn+Q44GbgeOB+4Jyq2tNXthp4AdgI\nLATuAq6Yg14kSdIcOeCQUFX/oTG2Blizn9c8B1zVPSRJ0jzkvRskSVKTIUGSJDUZEiRJUpMhQZIk\nNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZ\nEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIk\nSVKTIUGSJDUZEiRJUpMhQZIkNQ0VEpJcnuTRJLPd44EkvzhQc12SJ5M8k+SeJKcMbF+YZH2SmSS7\nkmxMcuJcHIwkSZo7w84kfAO4BlgJTACfB25PsgIgyTXAlcBlwCpgN3B3kgV9+1gHnAucD5wJnATc\ndgDHIEmSDoKjhymuqj8bGLo2yfuANwNbgKuBtVV1B0CSC4GdwHnAhiSLgEuAC6rqvq7mYmBLklVV\ntfmAjkaSJM2ZkdckJDkqyQXAccADSU4GlgL37q2pqqeBh4AzuqHT6AWT/pqtwPa+GkmSNA8MNZMA\nkORNwIPAscAu4N1VtTXJGUDRmznot5NeeABYAuzpwsNL1UiSpHlg6JAAfA04FVgM/ArwiSRnzmlX\nL2l192v7TXYPSZKObFNTU0xNTe0zNjs7O/L+hg4JVfU88PXu6SNJVtFbi3A9EHqzBf2zCUuAR7qf\ndwALkiwamE1Y0m17GTfSWzMpSZIGTU5OMjm57x/O09PTTExMjLS/ufiehKOAhVW1jd4H/Vl7N3QL\nFU8HHuiGHgaeH6hZDiyjdwpDkiTNE0PNJCT5A+DP6S00fC3wHuBtwNldyTp6Vzw8BjwOrAWeAG6H\n3kLGJLcANyR5it6ahpuATV7ZIEnS/DLs6YYTgY8DrwdmgS8DZ1fV5wGq6vokxwE3A8cD9wPnVNWe\nvn2sBl4ANgILgbuAKw7kICRJ0twb9nsSLn0FNWuANfvZ/hxwVfeQJEnzlPdukCRJTYYESZLUZEiQ\nJElNhgRJktRkSJAkSU2GBEmS1GRIkCRJTYYESZLUZEiQJElNhgRJktRkSJAkSU2GBEmS1GRIkCRJ\nTYYESZLUZEiQJElNhgRJktRkSJAkSU2GBEmS1GRIkCRJTYYESZLUZEiQJElNhgRJktRkSJAkSU2G\nBEmS1GRIkCRJTYYESZLUZEiQJElNhgRJktQ0VEhI8sEkm5M8nWRnks8m+alG3XVJnkzyTJJ7kpwy\nsH1hkvVJZpLsSrIxyYkHejCSJGnuDDuT8FbgI8DpwNuBY4C/SPLDewuSXANcCVwGrAJ2A3cnWdC3\nn3XAucD5wJnAScBtIx6DJEk6CI4epriq3tn/PMlFwD8DE8AXuuGrgbVVdUdXcyGwEzgP2JBkEXAJ\ncEFV3dfVXAxsSbKqqjaPfjiSJGmuDBUSGo4HCvguQJKTgaXAvXsLqurpJA8BZwAbgNO639tfszXJ\n9q7GkDBPbN++nZmZmXG3MZITTjiBZcuWjbsNSXpVGzkkJAm90wZfqKqvdsNL6YWGnQPlO7ttAEuA\nPVX19H5qNGbbt29n+fIVPPvsM+NuZSTHHnscW7duMShI0gE4kJmEjwI/A7xljnp5BVYDiwfGJruH\n5tLMzEwXEG4FVoy7nSFt4dln38vMzIwhQdIRZWpqiqmpqX3GZmdnR97fSCEhyR8B7wTeWlXf6tu0\nAwi92YL+2YQlwCN9NQuSLBqYTVjSbduPG4GVo7Sska3A91ySXh0mJyeZnNz3D+fp6WkmJiZG2t/Q\n35PQBYRfBv59VW3v31ZV2+h90J/VV7+I3tUQD3RDDwPPD9QsB5YBDw7bjyRJOjiGmklI8lF6c/vv\nAnYnWdJtmq2qZ7uf1wHXJnkMeBxYCzwB3A4/WMh4C3BDkqeAXcBNwCavbJAkaf4Y9nTD5fQWJv71\nwPjFwCcAqur6JMcBN9O7+uF+4Jyq2tNXvxp4AdgILATuAq4YtnlJknTwDPs9Ca/o9ERVrQHW7Gf7\nc8BV3UOSJM1D3rtBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGS\nJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1\nGRIkSVKTIUGSJDUZEiRJUpMhQZIkNRkSJElSkyFBkiQ1GRIkSVKTIUGSJDUNHRKSvDXJnyb5ZpIX\nk7yrUXNdkieTPJPkniSnDGxfmGR9kpkku5JsTHLigRyIJEmaW6PMJLwG+Fvg/UANbkxyDXAlcBmw\nCtgN3J1kQV/ZOuBc4HzgTOAk4LYRepEkSQfJ0cO+oKruAu4CSJJGydXA2qq6o6u5ENgJnAdsSLII\nuAS4oKru62ouBrYkWVVVm0c6EkmSNKfmdE1CkpOBpcC9e8eq6mngIeCMbug0euGkv2YrsL2vRpIk\njdlcL1xcSu8UxM6B8Z3dNoAlwJ4uPLxUjSRJGjOvbpAkSU1Dr0l4GTuA0Jst6J9NWAI80lezIMmi\ngdmEJd22/VgNLB4Ym+wekiQd2aamppiamtpnbHZ2duT9zWlIqKptSXYAZwFfBugWKp4OrO/KHgae\n72o+29UsB5YBD+7/N9wIrJzLliVJOmxMTk4yObnvH87T09NMTEyMtL+hQ0KS1wCn0JsxAHhjklOB\n71bVN+hd3nhtkseAx4G1wBPA7dBbyJjkFuCGJE8Bu4CbgE1e2SBJ0vwxykzCacBf0VugWMAfduMf\nBy6pquuTHAfcDBwP3A+cU1V7+vaxGngB2AgspHdJ5RUjHYEkSTooRvmehPt4mQWPVbUGWLOf7c8B\nV3UPSZI0D3l1gyRJajIkSJKkJkOCJElqMiRIkqQmQ4IkSWoyJEiSpCZDgiRJajIkSJKkJkOCJElq\nMiRIkqQmQ4IkSWqa01tFSzow27dvZ2ZmZtxtjOSEE05g2bJl425D0hwyJEjzxPbt21m+fAXPPvvM\nuFsZybHHHsfWrVsMCtJhxJAgzRMzMzNdQLgVWDHudoa0hWeffS8zMzOGBOkwYkiQ5p0VwMpxNyFJ\nLlyUJElthgRJktRkSJAkSU2GBEmS1GRIkCRJTYYESZLUZEiQJElNhgRJktRkSJAkSU1+46KkI5o3\n1ZJemiFB0hHLm2pJ+2dIkHTE8qZa0v4ZEiTJm2odUlNTU0xOTo67Db0CY124mOSKJNuSfC/JF5P8\n/Dj7kSQdfFNTU+NuQa/Q2EJCkl8D/hD4PeDfAo8Cdyc5YVw9SZKkfzHOmYTVwM1V9Ymq+hpwOfAM\ncMkYe5IkSZ2xrElIcgwwAfzB3rGqqiR/CZwxjp4kSYfG9773Paanp8fdxkiOtMtOx7Vw8QTgh4Cd\nA+M7geWN+mN7//m/wJcOZl9z7EUA/u7v/o5PfepTY+5lONu2bet+uhPYMs5WRtDr/c4772TLlldP\n777nh57v+aE3MzPDvfd+nomJiXG3MpJjjlnIhz/8PznhhFfPmfF/+f9872fpK5eqmttuXskvTV4P\nfBM4o6oe6hv/n8CZVXXGQP2vA6+uT1lJkuaX91TVp4d5wbhmEmaAF4AlA+NLgB2N+ruB9wCPA88e\n1M4kSTq8HAv8BL3P0qGMZSYBIMkXgYeq6urueYDtwE1V9eGxNCVJkn5gnF+mdAPwsSQPA5vpXe1w\nHPCxMfYkSZI6YwsJVbWh+06E6+idZvhb4B1V9e1x9SRJkv7F2E43SJKk+W2sX8ssSZLmL0OCJElq\nmtchIclbk/xpkm8meTHJu8bd0+EuyQeTbE7ydJKdST6b5KfG3dfhLMnlSR5NMts9Hkjyi+Pu60iR\n5APdvy83jLuXw1mS3+ve5/7HV8fd1+EuyUlJPplkJskz3b81r/iWp/M6JACvobeg8f2AiycOjbcC\nHwFOB94OHAP8RZIfHmtXh7dvANfQu1fxBPB54PYkK8ba1RGgu/PsZfRuMKeD7yv0Fqov7R6/MN52\nDm9Jjgc2Ac8B76B3T/TfAp56pfsY5yWQL6uq7gLugh98j4IOsqp6Z//zJBcB/0zvw+sL4+jpcFdV\nfzYwdG2S9wFv5tX3XcGvGkl+BLgVuBT43TG3c6R43ivYDqkPANur6tK+sX8aZgfzfSZB43c8vVmc\n7467kSNBkqOSXEDvO0MeHHc/h7n1wOeq6vPjbuQI8pPd6eN/THJrkh8fd0OHuV8CvpRkQ3f6eDrJ\npS/7qj7zeiZB49XN3qwDvlBVnjs8iJK8iV4oOBbYBby7u4W6DoIuiP0ccNq4ezmCfBG4CNgKvB5Y\nA/xNkjdV1e4x9nU4eyPwPuAPgf8OrAJuSvJcVX3ylezAkKD9+SjwM8Bbxt3IEeBrwKnAYuBXgE8k\nOdOgMPeSvIFe+H17VX1/3P0cKaqq/74BX0mymd7U968CfzKerg57RwGbq2rv6bRHuz9ILgdeUUjw\ndIOakvwR8E7g31XVt8bdz+Guqp6vqq9X1SNV9Tv0FtJdPe6+DlMTwI8C00m+n+T7wNuAq5Pscf3T\noVFVs8A/AKeMu5fD2Lf41+uatgDLXukOnEnQv9IFhF8G3lZV28fdzxHqKGDhuJs4TP0l8LMDYx+j\n94/nh8qvoT0kuoWjpwCfGHcvh7FNwPKBseUMsXhxXoeEJK+h9z/R3mT/xiSnAt+tqm+Mr7PDV5KP\nApPAu4DdSfbeznu2qrxN90GQ5A+AP6d3F9TX0rst+tuAs8fZ1+GqO/+9zxqbJLuB71SVV5McJEk+\nDHyO3gfUjwG/D3wfmBpnX4e5G4FNST4IbKB3afulwG+80h3M65BAb1HRX9FbXV/0Fl8AfBy4ZFxN\nHeYup/de//XA+MWY+A+WE+n9P/16YBb4MnC2q+4PKWcPDr43AJ8GXgd8m94l1W+uqu+MtavDWFV9\nKcm7gQ/Ru8x3G3B1VX3mle7DGzxJkqQmFy5KkqQmQ4IkSWoyJEiSpCZDgiRJajIkSJKkJkOCJElq\nMiRIkqQmQ4IkSWoyJEiSpCZDgiRJajIkSJKkpv8PZ+4iE7WJJxgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76e4cb8f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = np.int32(np.random.exponential(.8, size=(1000))) + 1\n",
    "plt.hist(num_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5000 clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:07:45.499359Z",
     "start_time": "2018-06-27T23:07:45.488978Z"
    }
   },
   "outputs": [],
   "source": [
    "clients = [Client(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 1)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T23:10:34.255065Z",
     "start_time": "2018-06-27T23:10:02.864235Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 19.20587\n",
      "[ModelCheckpoint] New best model with 0.75450 validation accuracy\n",
      "[2/48] training loss across clients 635.15194\n",
      "validation: 0.746 accuracy\n",
      "[3/48] training loss across clients 230.04839\n",
      "[ModelCheckpoint] New best model with 0.92910 validation accuracy\n",
      "[4/48] training loss across clients 17.15949\n",
      "[ModelCheckpoint] New best model with 0.97490 validation accuracy\n",
      "[5/48] training loss across clients 4.89408\n",
      "[ModelCheckpoint] New best model with 0.98160 validation accuracy\n",
      "[6/48] training loss across clients 1.49444\n",
      "validation: 0.981 accuracy\n",
      "[7/48] training loss across clients 8.19963\n",
      "validation: 0.979 accuracy\n",
      "[8/48] training loss across clients 3.83776\n",
      "[ModelCheckpoint] New best model with 0.98360 validation accuracy\n",
      "[9/48] training loss across clients 0.36501\n",
      "validation: 0.982 accuracy\n",
      "[10/48] training loss across clients 0.58462\n",
      "validation: 0.978 accuracy\n",
      "[11/48] training loss across clients 0.57726\n",
      "validation: 0.979 accuracy\n",
      "[12/48] training loss across clients 0.44594\n",
      "validation: 0.979 accuracy\n",
      "[13/48] training loss across clients 0.26947\n",
      "validation: 0.982 accuracy\n",
      "[14/48] training loss across clients 0.12269\n",
      "validation: 0.979 accuracy\n",
      "[15/48] training loss across clients 0.13385\n",
      "validation: 0.982 accuracy\n",
      "[16/48] training loss across clients 0.05754\n",
      "validation: 0.980 accuracy\n",
      "[17/48] training loss across clients 0.02902\n",
      "validation: 0.978 accuracy\n",
      "[18/48] training loss across clients 0.09605\n",
      "validation: 0.975 accuracy\n",
      "[19/48] training loss across clients 0.03727\n",
      "validation: 0.973 accuracy\n",
      "[20/48] training loss across clients 0.03913\n",
      "validation: 0.981 accuracy\n",
      "[21/48] training loss across clients 0.05153\n",
      "validation: 0.980 accuracy\n",
      "[22/48] training loss across clients 0.02739\n",
      "validation: 0.980 accuracy\n",
      "[23/48] training loss across clients 0.03089\n",
      "validation: 0.982 accuracy\n",
      "[24/48] training loss across clients 0.02350\n",
      "validation: 0.978 accuracy\n",
      "[25/48] training loss across clients 0.02712\n",
      "validation: 0.981 accuracy\n",
      "[26/48] training loss across clients 0.02529\n",
      "[ModelCheckpoint] New best model with 0.98490 validation accuracy\n",
      "[27/48] training loss across clients 0.00558\n",
      "validation: 0.979 accuracy\n",
      "[28/48] training loss across clients 0.02784\n",
      "validation: 0.980 accuracy\n",
      "[29/48] training loss across clients 0.00139\n",
      "validation: 0.985 accuracy\n",
      "[30/48] training loss across clients 0.00966\n",
      "validation: 0.975 accuracy\n",
      "[31/48] training loss across clients 0.00495\n",
      "validation: 0.975 accuracy\n",
      "[32/48] training loss across clients 0.00301\n",
      "validation: 0.981 accuracy\n",
      "[33/48] training loss across clients 0.00560\n",
      "validation: 0.980 accuracy\n",
      "[34/48] training loss across clients 0.00014\n",
      "validation: 0.982 accuracy\n",
      "[35/48] training loss across clients 0.00268\n",
      "validation: 0.980 accuracy\n",
      "[36/48] training loss across clients 0.00329\n",
      "validation: 0.983 accuracy\n",
      "[37/48] training loss across clients 0.00329\n",
      "validation: 0.982 accuracy\n",
      "[38/48] training loss across clients 0.00428\n",
      "validation: 0.978 accuracy\n",
      "[39/48] training loss across clients 0.00144\n",
      "validation: 0.976 accuracy\n",
      "[40/48] training loss across clients 0.00028\n",
      "validation: 0.981 accuracy\n",
      "[41/48] training loss across clients 0.00092\n",
      "validation: 0.984 accuracy\n",
      "[42/48] training loss across clients 0.00090\n",
      "validation: 0.983 accuracy\n",
      "[43/48] training loss across clients 0.00068\n",
      "validation: 0.981 accuracy\n",
      "[44/48] training loss across clients 0.00032\n",
      "validation: 0.984 accuracy\n",
      "[45/48] training loss across clients 0.00029\n",
      "validation: 0.985 accuracy\n",
      "[46/48] training loss across clients 0.00241\n",
      "validation: 0.977 accuracy\n",
      "[47/48] training loss across clients 0.00034\n",
      "validation: 0.981 accuracy\n",
      "[48/48] training loss across clients 0.00110\n",
      "[ModelCheckpoint] New best model with 0.98650 validation accuracy\n"
     ]
    }
   ],
   "source": [
    "server = Server(clients)\n",
    "server.fit(optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, 10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The model quality improved from 70% to >98% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplifications made:\n",
    "\n",
    "- All users sample from the same distribution\n",
    "- `ModelCheckpoint` cannot be based on validation data in the actual implementation\n",
    "- Users should run more than one SGD iteration locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:04:32.139661Z",
     "start_time": "2018-05-22T18:04:32.125608Z"
    }
   },
   "source": [
    "## To make fitting easier\n",
    "\n",
    "- Fair initialization\n",
    "- Normalize data (0-center)\n",
    "- Remove features with a value of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still missing\n",
    "\n",
    "- Implement frequency part (switch from one-hot encoding to up to sum of 10 and add multiplicative factor)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1196px",
    "left": "0px",
    "right": "1068px",
    "top": "160px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
