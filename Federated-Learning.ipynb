{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frecency Sampling\n",
    "\n",
    "To be able to quickly prototype the federated learning algorithm, a dataset is required.\n",
    "This notebook is based on a fake frecency dataset that was designed to be very interpretable and at the same time close to the actual data.\n",
    "The assumption for the data generation is that the current frecency algorithm is perfect. By sampling based on this axiom, we can check if the algorithm actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are weights that describe how common certain features are. For `recency` we assume a uniform distribution over time, for `type` numbers were chosen that intuitively seem to be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_weights = {\n",
    "    \"visited\": 0.6,\n",
    "    \"typed\": 0.2,\n",
    "    \"bookmarked\": 0.1,\n",
    "    \"other_type\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_weights = {\n",
    "    \"4-days\": 0.03,\n",
    "    \"14-days\": 0.05,\n",
    "    \"31-days\": 0.1,\n",
    "    \"90-days\": 0.32,\n",
    "    \"other_recency\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simulation, it seems to be a fair assumption that `type` and `recency` are independent of each other.\n",
    "This means we can just multiply the probabilities.\n",
    "\n",
    "This is probably not completely true, since users likely visit bookmarks more often, but it makes things easier here and the probabilities are hard to estimate well anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dicts_multiplicatively(dict1, dict2):\n",
    "    \"\"\"\n",
    "    A new dict is created that contains all pairs of the two input dicts.\n",
    "    The values correspond to the products of the values.\n",
    "    \"\"\"\n",
    "    weights = {}\n",
    "\n",
    "    for key1, weight1 in dict1.items():\n",
    "        for key2, weight2 in dict2.items():\n",
    "            key = (key1, key2)\n",
    "            weight = weight1 * weight2\n",
    "            weights[key] = weight\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = combine_dicts_multiplicatively(type_weights, recency_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-hot representation makes it easier to implement the rest of the formulas. numpy allows us to generate this easily using a permutation of the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(num_choices, vector):\n",
    "    return np.eye(num_choices)[vector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input vector to the model is 20-dimensional: One field for every combination of `type` and `recency`.\n",
    "In the frecency algorithm, we consider the last ten visits to the URL.\n",
    "Thus, the sum of all elements of the vector is a natural number between 1 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_weighted(num_samples, weight_dict):\n",
    "    \"\"\"Randomly sample from a dict using the values as probabilities\"\"\"\n",
    "    num_choices = len(weight_dict)\n",
    "    choice_weights = weight_dict.values()\n",
    "    samples = np.random.choice(num_choices, num_samples, p=choice_weights)\n",
    "    return one_hot(num_choices, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_url_features(num_samples):\n",
    "    return sample_weighted(num_samples, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the target labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the weights found in the current frecency algorithm. Based on the one-hot encoding, this is just a linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_points = {\n",
    "    \"visited\": 1.2,\n",
    "    \"typed\": 2,\n",
    "    \"bookmarked\": 1.4,\n",
    "    \"other_type\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recency_points = {\n",
    "    \"4-days\": 100,\n",
    "    \"14-days\": 70,\n",
    "    \"31-days\": 50,\n",
    "    \"90-days\": 30,\n",
    "    \"other_recency\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frecency_points_dict = combine_dicts_multiplicatively(type_points, recency_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure that the order of keys is the same everywhere\n",
    "key_order = weights.keys()\n",
    "frecency_points = np.array([frecency_points_dict[key] for key in key_order])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all these preparations, an arbitrary number of frecency scores can be computed using a single matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frecency(url_features):\n",
    "    return url_features.dot(frecency_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are sampling from the above distributions and then call the frecency function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(num_samples):\n",
    "    X = sample_url_features(num_samples)\n",
    "    y = frecency(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a model, we sample a lot of these scores and also add noise on top to make the problem more similar to the real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e6)\n",
    "noise = np.random.normal(0, 2, size=(n))\n",
    "X, y = sample(n)\n",
    "y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting coefficients are extremely close to the actual frecency weights. How close they are depends on how much noise we add to the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(120.00740659137126, 120.0),\n",
       " (36.004578642260974, 36.0),\n",
       " (0.021075250379209241, 0.0),\n",
       " (98.028286000507634, 98.0),\n",
       " (14.023348451486875, 14.0),\n",
       " (20.014400627354195, 20.0),\n",
       " (0.0024597203014381187, 0.0),\n",
       " (140.00408148593684, 140.0),\n",
       " (-0.078562045852951831, 0.0),\n",
       " (70.024480698407487, 70.0),\n",
       " (199.99585230509933, 200.0),\n",
       " (42.027334912205404, 42.0),\n",
       " (99.99929024256339, 100.0),\n",
       " (0.010894382049548968, 0.0),\n",
       " (59.992257784618502, 60.0),\n",
       " (140.03507955810906, 140.0),\n",
       " (12.000968581417023, 12.0),\n",
       " (59.997861448712243, 60.0),\n",
       " (83.993722997329556, 84.0),\n",
       " (-0.038365851254008314, 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(model.coef_, frecency_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00740659,  0.00457864,  0.02107525,  0.028286  ,  0.02334845,\n",
       "        0.01440063,  0.00245972,  0.00408149, -0.07856205,  0.0244807 ,\n",
       "       -0.00414769,  0.02733491, -0.00070976,  0.01089438, -0.00774222,\n",
       "        0.03507956,  0.00096858, -0.00213855, -0.006277  , -0.03836585])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ - frecency_points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
